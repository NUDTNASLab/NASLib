[{"experiment_type":"vary_train_size","search_space":"nasbench101","dataset":"cifar10","predictor":"gp","uniform_random":1,"test_size":200,"train_size_single":10,"train_size_list":[5,8,14,24,42,71,121,205,347,589,1000],"fidelity_single":5,"fidelity_list":[1,2,3,4,5,7,10,14,18,25,33,44,60,80,106],"out_dir":"p101_60","max_hpo_time":900,"seed":73,"search":{"seed":1000,"batch_size":256,"data_size":25000,"cutout":false,"cutout_length":16,"cutout_prob":1.0,"train_portion":0.7},"eval_only":false,"resume":false,"model_path":null,"save":"p101_60/cifar10/predictors/gp/73","data":"/home/shalag/NASLib/naslib/data"},{"mae":3.721026047905799,"rmse":6.949231211715736,"pearson":0.013628227447386388,"spearman":0.150227090106247,"kendalltau":0.09869991710620186,"kt_2dec":0.12550642328980136,"kt_1dec":0.05395420632951172,"precision_10":0.1,"precision_20":0.1,"train_size":5,"fidelity":5,"train_time":5460.365051269531,"fit_time":0.003717660903930664,"query_time":2.7545690536499023e-05,"cv_score":0},{"mae":3.6486376263201237,"rmse":6.987074168829367,"pearson":NaN,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":8,"fidelity":5,"train_time":8247.509094238281,"fit_time":0.0020589828491210938,"query_time":2.4074316024780272e-05,"cv_score":0},{"mae":3.5624620843897103,"rmse":7.15414523596885,"pearson":0.049599244108633894,"spearman":0.1125395301512925,"kendalltau":0.07399601488771516,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.15,"train_size":14,"fidelity":5,"train_time":18089.37811279297,"fit_time":0.0021233558654785156,"query_time":2.657890319824219e-05,"cv_score":0},{"mae":3.6396733379758577,"rmse":6.995617696205669,"pearson":0.01580220782694275,"spearman":0.21099772776124684,"kendalltau":0.14260217028751263,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.1,"precision_20":0.25,"train_size":24,"fidelity":5,"train_time":28202.912231445312,"fit_time":0.0022695064544677734,"query_time":5.470752716064453e-05,"cv_score":0},{"mae":3.663150350783978,"rmse":6.97550074216267,"pearson":0.14154244474644118,"spearman":0.32532914024560095,"kendalltau":0.22077830055053982,"kt_2dec":0.06804810633407049,"kt_1dec":-0.05847096544260872,"precision_10":0.0,"precision_20":0.1,"train_size":42,"fidelity":5,"train_time":50740.61911010742,"fit_time":0.018938779830932617,"query_time":4.357099533081055e-05,"cv_score":0},{"mae":3.6754988077116884,"rmse":6.967850493796963,"pearson":0.06627697977911619,"spearman":0.36864300146855816,"kendalltau":0.24910647518738993,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.05,"train_size":71,"fidelity":5,"train_time":88733.88986206055,"fit_time":0.02001476287841797,"query_time":6.770730018615723e-05,"cv_score":0},{"mae":3.754263307098761,"rmse":6.942497480701125,"pearson":NaN,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":121,"fidelity":5,"train_time":140667.55960083008,"fit_time":0.004969120025634766,"query_time":3.28373908996582e-05,"cv_score":0},{"mae":3.0978878540646533,"rmse":6.540082312816534,"pearson":0.35166923418795804,"spearman":0.48228741200051417,"kendalltau":0.33076420278827445,"kt_2dec":0.331274361147014,"kt_1dec":0.33376070223406984,"precision_10":0.2,"precision_20":0.2,"train_size":205,"fidelity":5,"train_time":242740.22540283203,"fit_time":0.007639408111572266,"query_time":3.2867193222045896e-05,"cv_score":0},{"mae":3.7647236010075824,"rmse":6.941305051893098,"pearson":0.0,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":347,"fidelity":5,"train_time":413876.38818359375,"fit_time":0.012053251266479492,"query_time":3.574013710021973e-05,"cv_score":0},{"mae":3.792828022914017,"rmse":6.935717746594788,"pearson":0.20995361859460576,"spearman":0.40259200759811126,"kendalltau":0.27279729739258485,"kt_2dec":0.2753500805495956,"kt_1dec":0.1909752316054048,"precision_10":0.0,"precision_20":0.05,"train_size":589,"fidelity":5,"train_time":717210.7886047363,"fit_time":0.025768756866455078,"query_time":5.3671598434448244e-05,"cv_score":0},{"mae":3.2887773949510564,"rmse":6.615131680369415,"pearson":0.3466033427000115,"spearman":0.47194444148525994,"kendalltau":0.32713497045045736,"kt_2dec":0.32752294843201746,"kt_1dec":0.33217282728514,"precision_10":0.2,"precision_20":0.2,"train_size":1000,"fidelity":5,"train_time":1218198.9430236816,"fit_time":0.06578683853149414,"query_time":0.00011167287826538086,"cv_score":0}]