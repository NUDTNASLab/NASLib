[{"experiment_type":"vary_train_size","search_space":"nasbench101","dataset":"cifar10","predictor":"gp","uniform_random":1,"test_size":200,"train_size_single":10,"train_size_list":[5,8,14,24,42,71,121,205,347,589,1000],"fidelity_single":5,"fidelity_list":[1,2,3,4,5,7,10,14,18,25,33,44,60,80,106],"out_dir":"p101_20","max_hpo_time":900,"seed":20,"search":{"seed":1000,"batch_size":256,"data_size":25000,"cutout":false,"cutout_length":16,"cutout_prob":1.0,"train_portion":0.7},"eval_only":false,"resume":false,"model_path":null,"save":"p101_20/cifar10/predictors/gp/20","data":"/home/shalag/NASLib/naslib/data"},{"mae":4.892327314615249,"rmse":5.433266254445149,"pearson":NaN,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":5,"fidelity":5,"train_time":4511.693145751953,"fit_time":0.035318613052368164,"query_time":4.1271448135375974e-05,"cv_score":0},{"mae":4.0064893320431265,"rmse":4.607938122530099,"pearson":0.067537224127826,"spearman":0.13171090746659547,"kendalltau":0.0862904972079607,"kt_2dec":0.08786911319220238,"kt_1dec":0.07711588585879281,"precision_10":0.1,"precision_20":0.25,"train_size":8,"fidelity":5,"train_time":9878.65689086914,"fit_time":0.002115488052368164,"query_time":2.5577545166015625e-05,"cv_score":0},{"mae":3.8892797316823704,"rmse":4.546943651974836,"pearson":NaN,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":14,"fidelity":5,"train_time":16707.77996826172,"fit_time":0.0020589828491210938,"query_time":5.311369895935059e-05,"cv_score":0},{"mae":4.016125470399857,"rmse":4.619084557975725,"pearson":NaN,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":24,"fidelity":5,"train_time":28042.739959716797,"fit_time":0.0035033226013183594,"query_time":3.821253776550293e-05,"cv_score":0},{"mae":3.6847042179885396,"rmse":4.483332163159727,"pearson":0.13545437275832767,"spearman":0.20139939689187059,"kendalltau":0.13521029983316343,"kt_2dec":0.1545625412569836,"kt_1dec":0.08222800301431103,"precision_10":0.2,"precision_20":0.2,"train_size":42,"fidelity":5,"train_time":48936.09780883789,"fit_time":0.01777958869934082,"query_time":5.656599998474121e-05,"cv_score":0},{"mae":3.7047880906354673,"rmse":4.484624579303992,"pearson":0.052463345302705654,"spearman":0.19495599638422173,"kendalltau":0.13914405715766426,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.2,"precision_20":0.2,"train_size":71,"fidelity":5,"train_time":82493.89953613281,"fit_time":0.017328262329101562,"query_time":5.543231964111328e-05,"cv_score":0},{"mae":3.6873707620411103,"rmse":4.484926744466084,"pearson":0.0980317599043236,"spearman":0.11634043069847945,"kendalltau":0.08494853178788704,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.1,"precision_20":0.15,"train_size":121,"fidelity":5,"train_time":139964.6885986328,"fit_time":0.004670858383178711,"query_time":2.867460250854492e-05,"cv_score":0},{"mae":3.684621659594738,"rmse":4.478845266024673,"pearson":0.21869327812083392,"spearman":0.2365268061786219,"kendalltau":0.16627689613947774,"kt_2dec":0.17926116286997254,"kt_1dec":0.08790020135084865,"precision_10":0.1,"precision_20":0.15,"train_size":205,"fidelity":5,"train_time":247268.33883666992,"fit_time":0.008599519729614258,"query_time":3.048896789550781e-05,"cv_score":0},{"mae":3.1705417877961564,"rmse":4.095078194171718,"pearson":0.4194593941590781,"spearman":0.39765157442594296,"kendalltau":0.27369873077007756,"kt_2dec":0.27368735259142624,"kt_1dec":0.2758386257818052,"precision_10":0.0,"precision_20":0.05,"train_size":347,"fidelity":5,"train_time":416751.8504638672,"fit_time":0.012215137481689453,"query_time":3.656983375549316e-05,"cv_score":0},{"mae":3.2551327167708712,"rmse":4.115814806540611,"pearson":0.44256139710301196,"spearman":0.4196611504091131,"kendalltau":0.28741644861961896,"kt_2dec":0.2882108944420622,"kt_1dec":0.2932272375437578,"precision_10":0.0,"precision_20":0.15,"train_size":589,"fidelity":5,"train_time":723976.9869384766,"fit_time":0.025651216506958008,"query_time":5.4949522018432616e-05,"cv_score":0},{"mae":3.6541848805837294,"rmse":4.507557209807455,"pearson":0.1659916475575342,"spearman":0.3328342657802571,"kendalltau":0.2381940492771469,"kt_2dec":0.04029881019268246,"kt_1dec":0.08170111366270973,"precision_10":0.2,"precision_20":0.2,"train_size":1000,"fidelity":5,"train_time":1221744.8707580566,"fit_time":0.06360507011413574,"query_time":0.00012128353118896484,"cv_score":0}]