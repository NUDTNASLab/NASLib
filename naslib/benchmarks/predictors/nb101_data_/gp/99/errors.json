[{"experiment_type":"vary_train_size","search_space":"nasbench101","dataset":"cifar10","predictor":"gp","uniform_random":1,"test_size":200,"train_size_single":10,"train_size_list":[5,8,14,24,42,71,121,205,347,589,1000],"fidelity_single":5,"fidelity_list":[1,2,3,4,5,7,10,14,18,25,33,44,60,80,106],"out_dir":"p101_80","max_hpo_time":900,"seed":99,"search":{"seed":1000,"batch_size":256,"data_size":25000,"cutout":false,"cutout_length":16,"cutout_prob":1.0,"train_portion":0.7},"eval_only":false,"resume":false,"model_path":null,"save":"p101_80/cifar10/predictors/gp/99","data":"/home/shalag/NASLib/naslib/data"},{"mae":3.1679770288933793,"rmse":4.373608411574246,"pearson":0.05976052994678611,"spearman":0.0804011281550457,"kendalltau":0.05231235075293778,"kt_2dec":0.05635234635522588,"kt_1dec":0.02577169255872718,"precision_10":0.0,"precision_20":0.0,"train_size":5,"fidelity":5,"train_time":5712.356018066406,"fit_time":0.004677772521972656,"query_time":3.870368003845215e-05,"cv_score":0},{"mae":3.274614520434477,"rmse":4.597309591604051,"pearson":0.12096198386855296,"spearman":0.03876847689393613,"kendalltau":0.02536877965069843,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.1,"train_size":8,"fidelity":5,"train_time":9359.570129394531,"fit_time":0.0019278526306152344,"query_time":2.3878812789916992e-05,"cv_score":0},{"mae":2.9408508967256073,"rmse":3.8203006062653113,"pearson":0.35847799759413923,"spearman":0.3208444687936025,"kendalltau":0.2096920036764942,"kt_2dec":0.2108783331134957,"kt_1dec":0.21562527221275354,"precision_10":0.1,"precision_20":0.15,"train_size":14,"fidelity":5,"train_time":17056.76708984375,"fit_time":0.0020148754119873047,"query_time":2.597212791442871e-05,"cv_score":0},{"mae":3.054270376761755,"rmse":3.8007980678384787,"pearson":0.0,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":24,"fidelity":5,"train_time":28635.04510498047,"fit_time":0.002256631851196289,"query_time":3.038167953491211e-05,"cv_score":0},{"mae":3.012158146872951,"rmse":3.774520740187463,"pearson":0.3269858522405811,"spearman":0.277227448272226,"kendalltau":0.1862306654500245,"kt_2dec":0.18847931117603597,"kt_1dec":0.18378473229704723,"precision_10":0.0,"precision_20":0.15,"train_size":42,"fidelity":5,"train_time":49761.37521362305,"fit_time":0.026522397994995117,"query_time":5.582571029663086e-05,"cv_score":0},{"mae":3.074993440536442,"rmse":3.7843617558722378,"pearson":0.027118347145953226,"spearman":0.09362320858486654,"kendalltau":0.06802750673514615,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.05,"train_size":71,"fidelity":5,"train_time":85200.0209350586,"fit_time":0.024910926818847656,"query_time":5.500078201293945e-05,"cv_score":0},{"mae":3.0053080318445353,"rmse":3.7150116044251504,"pearson":0.4178567507730406,"spearman":0.3629133821070391,"kendalltau":0.24876066990769694,"kt_2dec":0.25187478745217395,"kt_1dec":0.26071901845866785,"precision_10":0.1,"precision_20":0.2,"train_size":121,"fidelity":5,"train_time":142845.27307128906,"fit_time":0.004631757736206055,"query_time":2.8507709503173826e-05,"cv_score":0},{"mae":3.0736047866867806,"rmse":3.783852455517023,"pearson":NaN,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":205,"fidelity":5,"train_time":241665.8262939453,"fit_time":0.007256269454956055,"query_time":3.095149993896484e-05,"cv_score":0},{"mae":3.032859969783016,"rmse":3.7411230719273876,"pearson":0.5117996366557127,"spearman":0.48976891697703306,"kendalltau":0.34854687669924833,"kt_2dec":0.35972331995987805,"kt_1dec":0.35898714216055744,"precision_10":0.2,"precision_20":0.25,"train_size":347,"fidelity":5,"train_time":411458.1242980957,"fit_time":0.011688709259033203,"query_time":3.687500953674316e-05,"cv_score":0},{"mae":3.0651496573001986,"rmse":3.7799565077417028,"pearson":0.4330517131664692,"spearman":0.5948271923654661,"kendalltau":0.4379617623005578,"kt_2dec":0.2656266335127792,"kt_1dec":NaN,"precision_10":0.1,"precision_20":0.3,"train_size":589,"fidelity":5,"train_time":711415.0081481934,"fit_time":0.025368928909301758,"query_time":5.4486989974975585e-05,"cv_score":0},{"mae":3.0657374913438376,"rmse":3.7825506318730606,"pearson":0.09627019567161162,"spearman":0.410966959864348,"kendalltau":0.29185703368850824,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.1,"precision_20":0.1,"train_size":1000,"fidelity":5,"train_time":1223055.3645935059,"fit_time":0.06479597091674805,"query_time":0.00010116338729858398,"cv_score":0}]