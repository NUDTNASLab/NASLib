[{"experiment_type":"vary_train_size","search_space":"nasbench101","dataset":"cifar10","predictor":"gp","uniform_random":1,"test_size":200,"train_size_single":10,"train_size_list":[5,8,14,24,42,71,121,205,347,589,1000],"fidelity_single":5,"fidelity_list":[1,2,3,4,5,7,10,14,18,25,33,44,60,80,106],"out_dir":"p101_0","max_hpo_time":900,"seed":1,"search":{"seed":1000,"batch_size":256,"data_size":25000,"cutout":false,"cutout_length":16,"cutout_prob":1.0,"train_portion":0.7},"eval_only":false,"resume":false,"model_path":null,"save":"p101_0/cifar10/predictors/gp/1","data":"/home/shalag/NASLib/naslib/data"},{"mae":3.1207667392219434,"rmse":3.966059989979866,"pearson":0.18035026011126595,"spearman":0.18475341274526147,"kendalltau":0.126205096869911,"kt_2dec":0.1278322279292217,"kt_1dec":0.13036508492720636,"precision_10":0.2,"precision_20":0.2,"train_size":5,"fidelity":5,"train_time":7270.18505859375,"fit_time":0.004764080047607422,"query_time":2.7828216552734375e-05,"cv_score":0},{"mae":3.1687552825062926,"rmse":3.998054563059884,"pearson":0.18633277718148092,"spearman":0.25732316482420475,"kendalltau":0.1726949719128364,"kt_2dec":0.17677808999034408,"kt_1dec":0.0697349095219399,"precision_10":0.1,"precision_20":0.15,"train_size":8,"fidelity":5,"train_time":12014.581176757812,"fit_time":0.0019500255584716797,"query_time":2.428889274597168e-05,"cv_score":0},{"mae":3.3630381190461436,"rmse":3.97785380628287,"pearson":0.07894784954601677,"spearman":0.19891113795892826,"kendalltau":0.1350692566537897,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.25,"train_size":14,"fidelity":5,"train_time":18874.449951171875,"fit_time":0.0020449161529541016,"query_time":3.256082534790039e-05,"cv_score":0},{"mae":3.258613675832748,"rmse":3.921591023491821,"pearson":0.0,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":24,"fidelity":5,"train_time":30624.062072753906,"fit_time":0.002388477325439453,"query_time":5.513310432434082e-05,"cv_score":0},{"mae":3.2542209242110802,"rmse":3.921111117156347,"pearson":0.06565489657916108,"spearman":0.04970883908096506,"kendalltau":0.03959554391076433,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.15,"train_size":42,"fidelity":5,"train_time":56244.21240234375,"fit_time":0.010658502578735352,"query_time":4.5069456100463866e-05,"cv_score":0},{"mae":3.2695255336969935,"rmse":3.9240795334590914,"pearson":0.022173314920613068,"spearman":0.14288098398436705,"kendalltau":0.09721739521630421,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.15,"train_size":71,"fidelity":5,"train_time":93390.07067871094,"fit_time":0.021752119064331055,"query_time":6.376266479492187e-05,"cv_score":0},{"mae":3.2854640769743373,"rmse":3.9306862326476653,"pearson":0.09827042016321386,"spearman":0.18815677203108006,"kendalltau":0.12810900369702233,"kt_2dec":0.17944128611223548,"kt_1dec":NaN,"precision_10":0.1,"precision_20":0.1,"train_size":121,"fidelity":5,"train_time":162821.76889038086,"fit_time":0.0046291351318359375,"query_time":2.952456474304199e-05,"cv_score":0},{"mae":3.1034110274782756,"rmse":3.8165900474754997,"pearson":0.2504643696112629,"spearman":0.32091021927797436,"kendalltau":0.21304426441583554,"kt_2dec":0.2132114131801328,"kt_1dec":0.21561276180161357,"precision_10":0.0,"precision_20":0.2,"train_size":205,"fidelity":5,"train_time":262270.9202270508,"fit_time":0.007405281066894531,"query_time":3.181338310241699e-05,"cv_score":0},{"mae":3.251528634543961,"rmse":3.9208586301766157,"pearson":0.19829890390029667,"spearman":0.346567824534447,"kendalltau":0.23644685406757504,"kt_2dec":0.05754878110987487,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.15,"train_size":347,"fidelity":5,"train_time":456351.78829956055,"fit_time":0.012761831283569336,"query_time":3.779172897338867e-05,"cv_score":0},{"mae":3.29925288292872,"rmse":3.938158481902021,"pearson":0.0,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":589,"fidelity":5,"train_time":739080.0894775391,"fit_time":0.026993274688720703,"query_time":5.822896957397461e-05,"cv_score":0},{"mae":3.2573887772937695,"rmse":3.901409582404228,"pearson":0.4874183791393183,"spearman":0.4900966408650786,"kendalltau":0.335706113624953,"kt_2dec":0.33888850663723097,"kt_1dec":0.3543506567254307,"precision_10":0.2,"precision_20":0.15,"train_size":1000,"fidelity":5,"train_time":1238722.24508667,"fit_time":0.06787323951721191,"query_time":0.00013597846031188966,"cv_score":0}]