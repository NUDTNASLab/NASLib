[{"experiment_type":"vary_train_size","search_space":"nasbench101","dataset":"cifar10","predictor":"gp","uniform_random":1,"test_size":200,"train_size_single":10,"train_size_list":[5,8,14,24,42,71,121,205,347,589,1000],"fidelity_single":5,"fidelity_list":[1,2,3,4,5,7,10,14,18,25,33,44,60,80,106],"out_dir":"p101_80","max_hpo_time":900,"seed":80,"search":{"seed":1000,"batch_size":256,"data_size":25000,"cutout":false,"cutout_length":16,"cutout_prob":1.0,"train_portion":0.7},"eval_only":false,"resume":false,"model_path":null,"save":"p101_80/cifar10/predictors/gp/80","data":"/home/shalag/NASLib/naslib/data"},{"mae":4.414710355978143,"rmse":4.828884447646926,"pearson":0.301484081715213,"spearman":0.24661249870788005,"kendalltau":0.16702853686827263,"kt_2dec":0.16490796309664757,"kt_1dec":0.18455224869019515,"precision_10":0.1,"precision_20":0.2,"train_size":5,"fidelity":5,"train_time":4070.10205078125,"fit_time":0.003415822982788086,"query_time":2.758145332336426e-05,"cv_score":0},{"mae":3.34997408003394,"rmse":3.8942501580762103,"pearson":0.1715600214333457,"spearman":0.2530397393788449,"kendalltau":0.1694854035657957,"kt_2dec":0.09726637790127435,"kt_1dec":NaN,"precision_10":0.1,"precision_20":0.1,"train_size":8,"fidelity":5,"train_time":6394.298034667969,"fit_time":0.0019335746765136719,"query_time":2.4794340133666993e-05,"cv_score":0},{"mae":2.9378841757731027,"rmse":3.5990779478014274,"pearson":0.2639959581342181,"spearman":0.360862124635381,"kendalltau":0.24518182823300502,"kt_2dec":0.21966540629517753,"kt_1dec":0.07528685831495015,"precision_10":0.0,"precision_20":0.2,"train_size":14,"fidelity":5,"train_time":15435.77978515625,"fit_time":0.002012014389038086,"query_time":2.5309324264526367e-05,"cv_score":0},{"mae":2.9728232249617577,"rmse":3.623753346355563,"pearson":NaN,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":24,"fidelity":5,"train_time":24219.692749023438,"fit_time":0.002259969711303711,"query_time":2.4912357330322264e-05,"cv_score":0},{"mae":2.896334032217661,"rmse":3.558541674726477,"pearson":NaN,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":42,"fidelity":5,"train_time":45036.38070678711,"fit_time":0.011995077133178711,"query_time":5.901217460632324e-05,"cv_score":0},{"mae":2.9333558745787185,"rmse":3.5960729029851115,"pearson":0.0,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":71,"fidelity":5,"train_time":76287.08215332031,"fit_time":0.02354907989501953,"query_time":7.789969444274903e-05,"cv_score":0},{"mae":2.7820026632820327,"rmse":3.398750985500431,"pearson":0.47855856004341313,"spearman":0.39411809887281224,"kendalltau":0.26644939894509717,"kt_2dec":0.26817434096307896,"kt_1dec":0.2723396856144391,"precision_10":0.0,"precision_20":0.15,"train_size":121,"fidelity":5,"train_time":136587.73541259766,"fit_time":0.0047304630279541016,"query_time":3.0211210250854493e-05,"cv_score":0},{"mae":2.475711581551827,"rmse":3.089863349829242,"pearson":0.503396627789865,"spearman":0.46081831984707905,"kendalltau":0.31563695585268464,"kt_2dec":0.3163954173468436,"kt_1dec":0.3191955545986428,"precision_10":0.1,"precision_20":0.25,"train_size":205,"fidelity":5,"train_time":239290.53497314453,"fit_time":0.006953239440917969,"query_time":3.021240234375e-05,"cv_score":0},{"mae":2.391624559698741,"rmse":3.0260259844801616,"pearson":0.524527464962853,"spearman":0.511616640473242,"kendalltau":0.35474509536117627,"kt_2dec":0.35506006069813384,"kt_1dec":0.35839724252693017,"precision_10":0.2,"precision_20":0.4,"train_size":347,"fidelity":5,"train_time":411957.7512817383,"fit_time":0.012201070785522461,"query_time":3.6273002624511715e-05,"cv_score":0},{"mae":2.152338221207866,"rmse":2.8071115318170117,"pearson":0.6122225481101268,"spearman":0.5855207223410555,"kendalltau":0.4183462191494707,"kt_2dec":0.4186175531476724,"kt_1dec":0.422411389264644,"precision_10":0.2,"precision_20":0.35,"train_size":589,"fidelity":5,"train_time":708190.1690063477,"fit_time":0.026795387268066406,"query_time":5.398154258728027e-05,"cv_score":0},{"mae":2.1210116293026235,"rmse":2.7457146591548947,"pearson":0.653604023741407,"spearman":0.6181376202060063,"kendalltau":0.43618678794587024,"kt_2dec":0.43637530456613227,"kt_1dec":0.43732341310388906,"precision_10":0.1,"precision_20":0.4,"train_size":1000,"fidelity":5,"train_time":1215792.8784484863,"fit_time":0.06780409812927246,"query_time":0.00010379672050476075,"cv_score":0}]