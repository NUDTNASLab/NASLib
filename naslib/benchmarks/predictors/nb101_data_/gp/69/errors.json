[{"experiment_type":"vary_train_size","search_space":"nasbench101","dataset":"cifar10","predictor":"gp","uniform_random":1,"test_size":200,"train_size_single":10,"train_size_list":[5,8,14,24,42,71,121,205,347,589,1000],"fidelity_single":5,"fidelity_list":[1,2,3,4,5,7,10,14,18,25,33,44,60,80,106],"out_dir":"p101_60","max_hpo_time":900,"seed":69,"search":{"seed":1000,"batch_size":256,"data_size":25000,"cutout":false,"cutout_length":16,"cutout_prob":1.0,"train_portion":0.7},"eval_only":false,"resume":false,"model_path":null,"save":"p101_60/cifar10/predictors/gp/69","data":"/home/shalag/NASLib/naslib/data"},{"mae":3.166897382923024,"rmse":3.7758868249377957,"pearson":0.08687675664354752,"spearman":-0.009764308011936706,"kendalltau":-0.005541298086522929,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":5,"fidelity":5,"train_time":6117.023773193359,"fit_time":0.0034401416778564453,"query_time":2.7210712432861327e-05,"cv_score":0},{"mae":2.9558543763981486,"rmse":3.6538382796847153,"pearson":0.06604233963914824,"spearman":0.024944082869339808,"kendalltau":0.018740604477120358,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.05,"train_size":8,"fidelity":5,"train_time":12759.82943725586,"fit_time":0.0019521713256835938,"query_time":2.4763345718383788e-05,"cv_score":0},{"mae":2.964507474278277,"rmse":3.650161090053611,"pearson":0.0074091323499299935,"spearman":0.13490306227027418,"kendalltau":0.09500330007023167,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.2,"train_size":14,"fidelity":5,"train_time":20429.488555908203,"fit_time":0.0020112991333007812,"query_time":2.5779008865356445e-05,"cv_score":0},{"mae":2.8443528281515,"rmse":3.5391296081816597,"pearson":0.26590861387158793,"spearman":0.247929080587402,"kendalltau":0.16874923395295657,"kt_2dec":0.16927155710725858,"kt_1dec":0.1761371137854895,"precision_10":0.0,"precision_20":0.1,"train_size":24,"fidelity":5,"train_time":34180.63735961914,"fit_time":0.0022416114807128906,"query_time":3.402352333068848e-05,"cv_score":0},{"mae":3.013631050731945,"rmse":3.6269820481286357,"pearson":0.2344940267351699,"spearman":0.1897093064713387,"kendalltau":0.12583151833268225,"kt_2dec":0.1260822517863031,"kt_1dec":0.12968085953020533,"precision_10":0.0,"precision_20":0.15,"train_size":42,"fidelity":5,"train_time":54301.81735229492,"fit_time":0.013778924942016602,"query_time":4.49526309967041e-05,"cv_score":0},{"mae":2.9752256101168366,"rmse":3.64783023378836,"pearson":0.15367793391059595,"spearman":0.16573734073120236,"kendalltau":0.11182785055986973,"kt_2dec":0.10404556187980779,"kt_1dec":-0.023094411620811918,"precision_10":0.0,"precision_20":0.1,"train_size":71,"fidelity":5,"train_time":94176.20101928711,"fit_time":0.013061285018920898,"query_time":4.4758319854736326e-05,"cv_score":0},{"mae":2.969660867097949,"rmse":3.6490468934521796,"pearson":0.011348540529795396,"spearman":-0.11141744359308209,"kendalltau":-0.09141467372338322,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":121,"fidelity":5,"train_time":159984.03869628906,"fit_time":0.004637956619262695,"query_time":2.9854774475097656e-05,"cv_score":0},{"mae":2.9858595137189083,"rmse":3.6499140987384515,"pearson":0.0,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":205,"fidelity":5,"train_time":265892.8649597168,"fit_time":0.007207155227661133,"query_time":3.0710697174072266e-05,"cv_score":0},{"mae":2.785478430989339,"rmse":3.3787477094651397,"pearson":0.4324814163500287,"spearman":0.3842932626718747,"kendalltau":0.26173761779688426,"kt_2dec":0.26215952033596024,"kt_1dec":0.2649368701902223,"precision_10":0.2,"precision_20":0.35,"train_size":347,"fidelity":5,"train_time":419505.5012512207,"fit_time":0.013020992279052734,"query_time":3.865361213684082e-05,"cv_score":0},{"mae":3.091300608296145,"rmse":3.715351161245139,"pearson":0.0,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":589,"fidelity":5,"train_time":715738.1673278809,"fit_time":0.026389122009277344,"query_time":5.493521690368652e-05,"cv_score":0},{"mae":3.0566064048632167,"rmse":3.6841050798274066,"pearson":0.3885244486838421,"spearman":0.40978410296219187,"kendalltau":0.296696414323258,"kt_2dec":0.31952861747308925,"kt_1dec":0.08274459520188122,"precision_10":0.2,"precision_20":0.2,"train_size":1000,"fidelity":5,"train_time":1235751.3495178223,"fit_time":0.06614065170288086,"query_time":0.00012084841728210449,"cv_score":0}]