[{"experiment_type":"vary_train_size","search_space":"asr","dataset":"dataset","predictor":"gp","uniform_random":1,"test_size":200,"train_size_single":10,"train_size_list":[5,8,14,24,42,71,121,205,347,589,1000],"fidelity_single":5,"fidelity_list":[1,2,2,3,4,5,6,8,10,13,16,20,25,32,40],"out_dir":"pasr_20","max_hpo_time":900,"seed":33,"search":{"seed":1000,"batch_size":256,"data_size":25000,"cutout":false,"cutout_length":16,"cutout_prob":1.0,"train_portion":0.7},"eval_only":false,"resume":false,"model_path":null,"save":"pasr_20/dataset/predictors/gp/33","data":"/home/zabergjg/NASLib/naslib/data"},{"mae":0.18884059059870256,"rmse":0.34708006147406717,"pearson":0.050137630171441426,"spearman":0.009017442347584783,"kendalltau":0.005795659440246942,"kt_2dec":0.020677637467672746,"kt_1dec":NaN,"precision_10":0.1,"precision_20":0.2,"train_size":5,"fidelity":5,"train_time":-5,"fit_time":0.004102468490600586,"query_time":1.9773244857788086e-05,"cv_score":0},{"mae":0.18932035919044918,"rmse":0.34829629904306364,"pearson":0.01809081699360696,"spearman":0.05884693640330063,"kendalltau":0.03915456268185744,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.05,"train_size":8,"fidelity":5,"train_time":-8,"fit_time":0.0020775794982910156,"query_time":1.7883777618408204e-05,"cv_score":0},{"mae":0.20916569747030736,"rmse":0.3206811873397363,"pearson":NaN,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":14,"fidelity":5,"train_time":-14,"fit_time":0.002162933349609375,"query_time":1.815915107727051e-05,"cv_score":0},{"mae":0.22227197003375374,"rmse":0.2961228083125179,"pearson":0.3141251857071855,"spearman":0.24037641932659745,"kendalltau":0.15943619470278578,"kt_2dec":0.16316012353354295,"kt_1dec":0.11348029665086501,"precision_10":0.1,"precision_20":0.25,"train_size":24,"fidelity":5,"train_time":-24,"fit_time":0.0023956298828125,"query_time":1.765251159667969e-05,"cv_score":0},{"mae":0.23482790612866808,"rmse":0.30167300620430865,"pearson":0.053365091869247996,"spearman":0.2138605282480453,"kendalltau":0.13510087844280544,"kt_2dec":0.08112496018904894,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.05,"train_size":42,"fidelity":5,"train_time":-42,"fit_time":0.00260162353515625,"query_time":1.791834831237793e-05,"cv_score":0},{"mae":0.2302735305897718,"rmse":0.30332607670355954,"pearson":0.07410742379934238,"spearman":0.19914993833951983,"kendalltau":0.12678301702661474,"kt_2dec":0.11491008825241593,"kt_1dec":0.08112496018904894,"precision_10":0.0,"precision_20":0.1,"train_size":71,"fidelity":5,"train_time":-71,"fit_time":0.0030858516693115234,"query_time":1.843094825744629e-05,"cv_score":0},{"mae":0.19975260162133054,"rmse":0.2706080250068688,"pearson":0.5187458905789493,"spearman":0.3872879965529314,"kendalltau":0.27432700504486907,"kt_2dec":0.2786655167729334,"kt_1dec":0.2834542413303028,"precision_10":0.1,"precision_20":0.3,"train_size":121,"fidelity":5,"train_time":-121,"fit_time":0.004003286361694336,"query_time":1.9762516021728516e-05,"cv_score":0},{"mae":0.16688727323373964,"rmse":0.21835802158253584,"pearson":0.6996444998682197,"spearman":0.47905091398824434,"kendalltau":0.31988020353137925,"kt_2dec":0.32328585362441475,"kt_1dec":0.3468475998853952,"precision_10":0.1,"precision_20":0.3,"train_size":205,"fidelity":5,"train_time":-205,"fit_time":0.005896806716918945,"query_time":2.2101402282714844e-05,"cv_score":0},{"mae":0.2472232337260894,"rmse":0.2940808680736336,"pearson":0.1769117771878915,"spearman":0.2872684950992802,"kendalltau":0.2218432907116163,"kt_2dec":0.11624518547146995,"kt_1dec":0.11619584970120266,"precision_10":0.2,"precision_20":0.25,"train_size":347,"fidelity":5,"train_time":-347,"fit_time":0.011072635650634766,"query_time":3.141403198242187e-05,"cv_score":0},{"mae":0.13969007231002953,"rmse":0.1872727852157384,"pearson":0.802768397562364,"spearman":0.5382544899267855,"kendalltau":0.35696776336110436,"kt_2dec":0.35911718369157264,"kt_1dec":0.40449717804285723,"precision_10":0.2,"precision_20":0.3,"train_size":589,"fidelity":5,"train_time":-589,"fit_time":0.021683931350708008,"query_time":4.510283470153809e-05,"cv_score":0},{"mae":0.20556663883340398,"rmse":0.2606569891698477,"pearson":0.562377746056557,"spearman":0.45168210518493135,"kendalltau":0.2937778176729586,"kt_2dec":0.31246575055080117,"kt_1dec":0.27544663885600074,"precision_10":0.1,"precision_20":0.3,"train_size":1000,"fidelity":5,"train_time":-1000,"fit_time":0.05883932113647461,"query_time":8.838415145874023e-05,"cv_score":0}]