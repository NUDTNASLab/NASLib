[{"experiment_type":"vary_train_size","search_space":"transbench101","dataset":"normal","predictor":"gp","uniform_random":1,"test_size":200,"train_size_single":10,"train_size_list":[5,8,14,24,42,71,121,205,347,589,1000],"fidelity_single":5,"fidelity_list":[1,2,3,4,5,6,7,8,9,10],"out_dir":"ptrans_0","max_hpo_time":900,"seed":4,"search":{"seed":1000,"batch_size":256,"data_size":25000,"cutout":false,"cutout_length":16,"cutout_prob":1.0,"train_portion":0.7},"eval_only":false,"resume":false,"model_path":null,"save":"ptrans_0/normal/predictors/gp/4","data":"/home/shalag/NASLib/naslib/data"},{"mae":0.0344396398365475,"rmse":0.06351655638390655,"pearson":0.04435884497525568,"spearman":0.11959963928478438,"kendalltau":0.09771095694336046,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":5,"fidelity":5,"train_time":86784.0,"fit_time":0.0032210350036621094,"query_time":1.4388561248779297e-05,"cv_score":0},{"mae":0.03461437691332539,"rmse":0.06428649676224105,"pearson":0.21406671200556632,"spearman":0.2457566322079445,"kendalltau":0.16391795372816334,"kt_2dec":NaN,"kt_1dec":0.21663284457581808,"precision_10":0.0,"precision_20":0.1,"train_size":8,"fidelity":5,"train_time":141542.0,"fit_time":0.001764535903930664,"query_time":1.2593269348144531e-05,"cv_score":0},{"mae":0.03589499660225641,"rmse":0.05420987801662023,"pearson":0.4069195226055442,"spearman":0.41073017690788977,"kendalltau":0.27333067376266745,"kt_2dec":0.2796055693461779,"kt_1dec":NaN,"precision_10":0.1,"precision_20":0.05,"train_size":14,"fidelity":5,"train_time":251456.0,"fit_time":0.001825571060180664,"query_time":1.3540983200073243e-05,"cv_score":0},{"mae":0.0398258447652025,"rmse":0.057538769499490036,"pearson":0.19380669165161624,"spearman":0.266394473440989,"kendalltau":0.21410573087457702,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.1,"precision_20":0.1,"train_size":24,"fidelity":5,"train_time":428173.0,"fit_time":0.0019268989562988281,"query_time":3.537297248840332e-05,"cv_score":0},{"mae":0.03023294067097827,"rmse":0.0474347021630844,"pearson":0.5831508863914191,"spearman":0.6698767782368846,"kendalltau":0.47726077214899026,"kt_2dec":0.485557627492659,"kt_1dec":0.24436955978114094,"precision_10":0.1,"precision_20":0.25,"train_size":42,"fidelity":5,"train_time":744845.0,"fit_time":0.01317286491394043,"query_time":4.49073314666748e-05,"cv_score":0},{"mae":0.02802086516942432,"rmse":0.04370188738713958,"pearson":0.6522088612259586,"spearman":0.7681871945266158,"kendalltau":0.566960858275602,"kt_2dec":0.5805136737640756,"kt_1dec":0.4748070938391768,"precision_10":0.2,"precision_20":0.4,"train_size":71,"fidelity":5,"train_time":1243101.0,"fit_time":0.012617349624633789,"query_time":4.246234893798828e-05,"cv_score":0},{"mae":0.03500901768378012,"rmse":0.05157307678837757,"pearson":0.6230502431108232,"spearman":0.7111674797757792,"kendalltau":0.5120676198673666,"kt_2dec":0.5439051760318507,"kt_1dec":NaN,"precision_10":0.1,"precision_20":0.2,"train_size":121,"fidelity":5,"train_time":2121723.0,"fit_time":0.003204822540283203,"query_time":1.658201217651367e-05,"cv_score":0},{"mae":0.04022986007950325,"rmse":0.05732411395947974,"pearson":0.1055348283948326,"spearman":0.6061787920454575,"kendalltau":0.42055514263262517,"kt_2dec":0.06679445737588553,"kt_1dec":NaN,"precision_10":0.1,"precision_20":0.15,"train_size":205,"fidelity":5,"train_time":3589126.0,"fit_time":0.00599980354309082,"query_time":2.0583868026733397e-05,"cv_score":0},{"mae":0.04010901751954126,"rmse":0.05730332896404046,"pearson":0.08760753027068338,"spearman":0.6650461097614867,"kendalltau":0.4697305287510742,"kt_2dec":0.06722318819096897,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.25,"train_size":347,"fidelity":5,"train_time":6111402.0,"fit_time":0.008487939834594727,"query_time":2.324223518371582e-05,"cv_score":0},{"mae":0.03799301412607051,"rmse":0.05557146503758672,"pearson":0.35487572514730176,"spearman":0.7210130756025824,"kendalltau":0.5180008464133554,"kt_2dec":0.22365572470971762,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.15,"train_size":589,"fidelity":5,"train_time":10428815.0,"fit_time":0.018002748489379883,"query_time":4.152536392211914e-05,"cv_score":0},{"mae":0.015062435748076617,"rmse":0.02379401555375538,"pearson":0.914609253315812,"spearman":0.8999315226457234,"kendalltau":0.7257461004212522,"kt_2dec":0.7551170677033198,"kt_1dec":0.6615167490853271,"precision_10":0.1,"precision_20":0.3,"train_size":1000,"fidelity":5,"train_time":17634961.0,"fit_time":0.05845999717712402,"query_time":9.571194648742676e-05,"cv_score":0}]