[08/24 13:36:10] nl.utils.utils INFO: experiment_type....................vary_train_size
[08/24 13:36:10] nl.utils.utils INFO: search_space.................................darts
[08/24 13:36:10] nl.utils.utils INFO: dataset....................................cifar10
[08/24 13:36:10] nl.utils.utils INFO: predictor......................................gcn
[08/24 13:36:10] nl.utils.utils INFO: uniform_random...................................1
[08/24 13:36:10] nl.utils.utils INFO: test_size......................................200
[08/24 13:36:10] nl.utils.utils INFO: train_size_single...............................10
[08/24 13:36:10] nl.utils.utils INFO: train_size_list[5, 8, 12, 20, 31, 50, 79, 126, 199, 316, 500]
[08/24 13:36:10] nl.utils.utils INFO: fidelity_single..................................5
[08/24 13:36:10] nl.utils.utils INFO: fidelity_list[1, 2, 3, 4, 5, 7, 10, 13, 17, 23, 30, 40, 54, 71, 95]
[08/24 13:36:10] nl.utils.utils INFO: out_dir....................................p301_34
[08/24 13:36:10] nl.utils.utils INFO: max_hpo_time...................................900
[08/24 13:36:10] nl.utils.utils INFO: seed............................................39
[08/24 13:36:10] nl.utils.utils INFO: searchbatch_size: 256
cutout: False
cutout_length: 16
cutout_prob: 1.0
data_size: 25000
seed: 1000
train_portion: 0.7
[08/24 13:36:10] nl.utils.utils INFO: eval_only....................................False
[08/24 13:36:10] nl.utils.utils INFO: resume.......................................False
[08/24 13:36:10] nl.utils.utils INFO: model_path....................................None
[08/24 13:36:10] nl.utils.utils INFO: save.............p301_34/cifar10/predictors/gcn/39
[08/24 13:36:10] nl.utils.utils INFO: data............./home/zabergjg/NASLib/naslib/data
[08/24 13:36:10] nl.search_spaces.core.graph WARNING: Update function could not be veryfied. Be cautious with the setting of `private_edge_data` in `update_edges()`
[08/24 13:36:10] nl.search_spaces.core.graph WARNING: Update function could not be veryfied. Be cautious with the setting of `private_edge_data` in `update_edges()`
[08/24 13:36:10] nl.search_spaces.core.graph WARNING: Update function could not be veryfied. Be cautious with the setting of `private_edge_data` in `update_edges()`
[08/24 13:36:10] nl.search_spaces.core.graph WARNING: Update function could not be veryfied. Be cautious with the setting of `private_edge_data` in `update_edges()`
[08/24 13:36:10] nl.search_spaces.core.graph WARNING: Update function could not be veryfied. Be cautious with the setting of `private_edge_data` in `update_edges()`
[08/24 13:36:28] nl.defaults.predictor_evaluator INFO: Load the test set
[08/24 13:38:03] nl.defaults.predictor_evaluator INFO: Load the training set
[08/24 13:42:10] nl.defaults.predictor_evaluator INFO: Fit the predictor
[08/24 13:42:13] nl.defaults.predictor_evaluator INFO: Compute evaluation metrics
[08/24 13:42:13] nl.defaults.predictor_evaluator INFO: train_size: 5, fidelity: 5, kendall tau 0.0911
[08/24 13:42:13] nl.defaults.predictor_evaluator INFO: mae: 0.5524, rmse: 0.7148, pearson: 0.1309, spearman: 0.1352, kendalltau: 0.0911, kt_2dec: nan, kt_1dec: nan, precision_10: 0.0, precision_20: 0.1, train_size: 5, fidelity: 5, train_time: 42135.0947, fit_time: 2.7606, query_time: 0.0001, hp_gcn_hidden: 144, hp_batch_size: 7, hp_lr: 0.0001, hp_wd: 0.0003, cv_score: 0, 
[08/24 13:42:13] nl.defaults.predictor_evaluator INFO: Fit the predictor
[08/24 13:42:15] nl.defaults.predictor_evaluator INFO: Compute evaluation metrics
[08/24 13:42:15] nl.defaults.predictor_evaluator INFO: train_size: 8, fidelity: 5, kendall tau 0.1208
[08/24 13:42:15] nl.defaults.predictor_evaluator INFO: mae: 0.5045, rmse: 0.6475, pearson: 0.1558, spearman: 0.1768, kendalltau: 0.1208, kt_2dec: 0.1236, kt_1dec: 0.1244, precision_10: 0.0, precision_20: 0.05, train_size: 8, fidelity: 5, train_time: 67566.8685, fit_time: 1.4925, query_time: 0.0001, hp_gcn_hidden: 144, hp_batch_size: 7, hp_lr: 0.0001, hp_wd: 0.0003, cv_score: 0, 
[08/24 13:42:15] nl.defaults.predictor_evaluator INFO: Fit the predictor
[08/24 13:42:16] nl.defaults.predictor_evaluator INFO: Compute evaluation metrics
[08/24 13:42:16] nl.defaults.predictor_evaluator INFO: train_size: 12, fidelity: 5, kendall tau 0.2624
[08/24 13:42:16] nl.defaults.predictor_evaluator INFO: mae: 0.4715, rmse: 0.5835, pearson: 0.4043, spearman: 0.3753, kendalltau: 0.2624, kt_2dec: 0.2683, kt_1dec: 0.268, precision_10: 0.0, precision_20: 0.15, train_size: 12, fidelity: 5, train_time: 96043.4109, fit_time: 1.4905, query_time: 0.0001, hp_gcn_hidden: 144, hp_batch_size: 7, hp_lr: 0.0001, hp_wd: 0.0003, cv_score: 0, 
[08/24 13:42:16] nl.defaults.predictor_evaluator INFO: Fit the predictor
[08/24 13:42:19] nl.defaults.predictor_evaluator INFO: Compute evaluation metrics
[08/24 13:42:19] nl.defaults.predictor_evaluator INFO: train_size: 20, fidelity: 5, kendall tau 0.2048
[08/24 13:42:19] nl.defaults.predictor_evaluator INFO: mae: 0.5615, rmse: 0.6747, pearson: 0.3189, spearman: 0.3005, kendalltau: 0.2048, kt_2dec: 0.2152, kt_1dec: 0.1862, precision_10: 0.1, precision_20: 0.25, train_size: 20, fidelity: 5, train_time: 151895.247, fit_time: 2.9109, query_time: 0.0001, hp_gcn_hidden: 144, hp_batch_size: 7, hp_lr: 0.0001, hp_wd: 0.0003, cv_score: 0, 
[08/24 13:42:19] nl.defaults.predictor_evaluator INFO: Fit the predictor
[08/24 13:42:25] nl.defaults.predictor_evaluator INFO: Compute evaluation metrics
[08/24 13:42:25] nl.defaults.predictor_evaluator INFO: train_size: 31, fidelity: 5, kendall tau 0.2113
[08/24 13:42:25] nl.defaults.predictor_evaluator INFO: mae: 0.4786, rmse: 0.5897, pearson: 0.3322, spearman: 0.3099, kendalltau: 0.2113, kt_2dec: 0.2174, kt_1dec: 0.2427, precision_10: 0.2, precision_20: 0.3, train_size: 31, fidelity: 5, train_time: 234626.9758, fit_time: 5.7795, query_time: 0.0001, hp_gcn_hidden: 144, hp_batch_size: 7, hp_lr: 0.0001, hp_wd: 0.0003, cv_score: 0, 
[08/24 13:42:25] nl.defaults.predictor_evaluator INFO: Fit the predictor
[08/24 13:42:35] nl.defaults.predictor_evaluator INFO: Compute evaluation metrics
[08/24 13:42:35] nl.defaults.predictor_evaluator INFO: train_size: 50, fidelity: 5, kendall tau 0.2067
[08/24 13:42:35] nl.defaults.predictor_evaluator INFO: mae: 0.5036, rmse: 0.6215, pearson: 0.3037, spearman: 0.3092, kendalltau: 0.2067, kt_2dec: 0.208, kt_1dec: 0.2286, precision_10: 0.0, precision_20: 0.2, train_size: 50, fidelity: 5, train_time: 383510.8759, fit_time: 10.0966, query_time: 0.0001, hp_gcn_hidden: 144, hp_batch_size: 7, hp_lr: 0.0001, hp_wd: 0.0003, cv_score: 0, 
[08/24 13:42:35] nl.defaults.predictor_evaluator INFO: Fit the predictor
[08/24 13:42:51] nl.defaults.predictor_evaluator INFO: Compute evaluation metrics
[08/24 13:42:51] nl.defaults.predictor_evaluator INFO: Error when computing metrics. ytest and test_pred are:
[08/24 13:42:51] nl.defaults.predictor_evaluator INFO: [93.05000305 93.13999939 93.91000366 92.30000305 93.04000092 92.76999664
 93.26999664 92.27999878 93.         93.5        93.55999756 93.20999908
 93.30000305 93.70999908 92.87000275 92.70999908 92.48999786 93.27999878
 92.91999817 93.08000183 92.98999786 93.41000366 93.51000214 92.87999725
 93.30000305 91.69000244 92.68000031 93.30999756 93.80000305 92.94000244
 92.45999908 93.06999969 94.40000153 92.81999969 94.12999725 93.63999939
 92.87999725 93.54000092 93.23000336 93.23999786 92.01999664 91.87000275
 93.44000244 92.88999939 93.65000153 93.22000122 93.76999664 93.55999756
 92.98999786 92.05000305 93.26999664 92.38999939 93.44000244 92.01999664
 91.         92.44000244 92.41000366 93.55999756 92.31999969 93.08999634
 93.65000153 93.68000031 93.18000031 93.81999969 93.11000061 92.79000092
 93.58999634 91.93000031 91.55999756 92.05000305 93.62999725 92.63999939
 92.48999786 93.33999634 93.86000061 93.69999695 92.76999664 92.51999664
 93.69999695 93.55999756 93.45999908 93.01999664 92.87000275 93.65000153
 91.44000244 91.66999817 92.59999847 92.51000214 92.62999725 93.05999756
 93.16999817 94.         92.12000275 92.31999969 93.58999634 93.63999939
 93.44000244 93.19999695 93.68000031 92.87999725 93.79000092 93.61000061
 92.69999695 92.87000275 92.77999878 93.38999939 92.58999634 93.19999695
 93.70999908 92.55000305 92.94999695 91.34999847 92.30000305 92.20999908
 92.86000061 93.26000214 93.20999908 93.19999695 93.26999664 93.38999939
 93.44000244 92.70999908 92.98000336 92.40000153 93.58000183 92.76000214
 92.76000214 92.25       92.84999847 92.83000183 93.37999725 91.79000092
 93.06999969 92.98000336 92.80000305 93.36000061 91.72000122 92.12999725
 93.23999786 93.45999908 92.69999695 92.76999664 93.18000031 94.05000305
 91.98999786 93.54000092 92.79000092 92.66000366 92.93000031 93.16999817
 91.88999939 92.54000092 93.84999847 92.83000183 93.26000214 93.23999786
 93.73999786 92.80000305 93.12999725 92.31999969 92.84999847 93.70999908
 91.63999939 91.91999817 93.81999969 92.69000244 93.25       92.43000031
 92.58999634 93.01000214 92.77999878 92.68000031 92.62000275 93.58999634
 93.61000061 93.47000122 93.61000061 92.30000305 93.94000244 93.75
 92.06999969 93.37999725 92.44000244 93.43000031 93.11000061 92.37000275
 92.29000092 92.58000183 92.58999634 93.51000214 91.75       93.47000122
 92.75       93.41000366 93.19000244 92.76000214 93.04000092 93.37999725
 92.41999817 91.88999939]
[08/24 13:42:51] nl.defaults.predictor_evaluator INFO: [92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088
 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088
 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088
 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088
 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088
 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088
 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088
 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088
 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088
 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088
 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088
 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088
 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088
 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088
 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088
 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088
 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088
 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088
 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088
 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088
 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088
 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088
 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088
 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088
 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088 92.88088]
[08/24 13:42:51] nl.defaults.predictor_evaluator INFO: train_size: 79, fidelity: 5, kendall tau nan
[08/24 13:42:51] nl.defaults.predictor_evaluator INFO: mae: 0.5045, rmse: 0.6181, pearson: nan, spearman: nan, kendalltau: nan, kt_2dec: nan, kt_1dec: nan, precision_10: 0.0, precision_20: 0.0, train_size: 79, fidelity: 5, train_time: 619765.9836, fit_time: 15.8097, query_time: 0.0001, hp_gcn_hidden: 144, hp_batch_size: 7, hp_lr: 0.0001, hp_wd: 0.0003, cv_score: 0, 
[08/24 13:42:51] nl.defaults.predictor_evaluator INFO: Fit the predictor
[08/24 13:43:17] nl.defaults.predictor_evaluator INFO: Compute evaluation metrics
[08/24 13:43:17] nl.defaults.predictor_evaluator INFO: train_size: 126, fidelity: 5, kendall tau 0.4415
[08/24 13:43:17] nl.defaults.predictor_evaluator INFO: mae: 0.4033, rmse: 0.5081, pearson: 0.6147, spearman: 0.6198, kendalltau: 0.4415, kt_2dec: 0.442, kt_1dec: 0.4566, precision_10: 0.4, precision_20: 0.45, train_size: 126, fidelity: 5, train_time: 985391.6208, fit_time: 25.8947, query_time: 0.0001, hp_gcn_hidden: 144, hp_batch_size: 7, hp_lr: 0.0001, hp_wd: 0.0003, cv_score: 0, 
[08/24 13:43:17] nl.defaults.predictor_evaluator INFO: Fit the predictor
[08/24 13:43:57] nl.defaults.predictor_evaluator INFO: Compute evaluation metrics
[08/24 13:43:57] nl.defaults.predictor_evaluator INFO: train_size: 199, fidelity: 5, kendall tau 0.5063
[08/24 13:43:57] nl.defaults.predictor_evaluator INFO: mae: 0.333, rmse: 0.4412, pearson: 0.7001, spearman: 0.6914, kendalltau: 0.5063, kt_2dec: 0.5073, kt_1dec: 0.5174, precision_10: 0.4, precision_20: 0.6, train_size: 199, fidelity: 5, train_time: 1560873.2048, fit_time: 40.3977, query_time: 0.0001, hp_gcn_hidden: 144, hp_batch_size: 7, hp_lr: 0.0001, hp_wd: 0.0003, cv_score: 0, 
[08/24 13:43:57] nl.defaults.predictor_evaluator INFO: Fit the predictor
[08/24 13:45:02] nl.defaults.predictor_evaluator INFO: Compute evaluation metrics
[08/24 13:45:02] nl.defaults.predictor_evaluator INFO: train_size: 316, fidelity: 5, kendall tau 0.4353
[08/24 13:45:02] nl.defaults.predictor_evaluator INFO: mae: 0.3827, rmse: 0.5003, pearson: 0.6045, spearman: 0.6121, kendalltau: 0.4353, kt_2dec: 0.4362, kt_1dec: 0.4501, precision_10: 0.4, precision_20: 0.35, train_size: 316, fidelity: 5, train_time: 2506742.9032, fit_time: 64.9381, query_time: 0.0001, hp_gcn_hidden: 144, hp_batch_size: 7, hp_lr: 0.0001, hp_wd: 0.0003, cv_score: 0, 
[08/24 13:45:02] nl.defaults.predictor_evaluator INFO: Fit the predictor
[08/24 13:46:45] nl.defaults.predictor_evaluator INFO: Compute evaluation metrics
[08/24 13:46:45] nl.defaults.predictor_evaluator INFO: Error when computing metrics. ytest and test_pred are:
[08/24 13:46:45] nl.defaults.predictor_evaluator INFO: [93.05000305 93.13999939 93.91000366 92.30000305 93.04000092 92.76999664
 93.26999664 92.27999878 93.         93.5        93.55999756 93.20999908
 93.30000305 93.70999908 92.87000275 92.70999908 92.48999786 93.27999878
 92.91999817 93.08000183 92.98999786 93.41000366 93.51000214 92.87999725
 93.30000305 91.69000244 92.68000031 93.30999756 93.80000305 92.94000244
 92.45999908 93.06999969 94.40000153 92.81999969 94.12999725 93.63999939
 92.87999725 93.54000092 93.23000336 93.23999786 92.01999664 91.87000275
 93.44000244 92.88999939 93.65000153 93.22000122 93.76999664 93.55999756
 92.98999786 92.05000305 93.26999664 92.38999939 93.44000244 92.01999664
 91.         92.44000244 92.41000366 93.55999756 92.31999969 93.08999634
 93.65000153 93.68000031 93.18000031 93.81999969 93.11000061 92.79000092
 93.58999634 91.93000031 91.55999756 92.05000305 93.62999725 92.63999939
 92.48999786 93.33999634 93.86000061 93.69999695 92.76999664 92.51999664
 93.69999695 93.55999756 93.45999908 93.01999664 92.87000275 93.65000153
 91.44000244 91.66999817 92.59999847 92.51000214 92.62999725 93.05999756
 93.16999817 94.         92.12000275 92.31999969 93.58999634 93.63999939
 93.44000244 93.19999695 93.68000031 92.87999725 93.79000092 93.61000061
 92.69999695 92.87000275 92.77999878 93.38999939 92.58999634 93.19999695
 93.70999908 92.55000305 92.94999695 91.34999847 92.30000305 92.20999908
 92.86000061 93.26000214 93.20999908 93.19999695 93.26999664 93.38999939
 93.44000244 92.70999908 92.98000336 92.40000153 93.58000183 92.76000214
 92.76000214 92.25       92.84999847 92.83000183 93.37999725 91.79000092
 93.06999969 92.98000336 92.80000305 93.36000061 91.72000122 92.12999725
 93.23999786 93.45999908 92.69999695 92.76999664 93.18000031 94.05000305
 91.98999786 93.54000092 92.79000092 92.66000366 92.93000031 93.16999817
 91.88999939 92.54000092 93.84999847 92.83000183 93.26000214 93.23999786
 93.73999786 92.80000305 93.12999725 92.31999969 92.84999847 93.70999908
 91.63999939 91.91999817 93.81999969 92.69000244 93.25       92.43000031
 92.58999634 93.01000214 92.77999878 92.68000031 92.62000275 93.58999634
 93.61000061 93.47000122 93.61000061 92.30000305 93.94000244 93.75
 92.06999969 93.37999725 92.44000244 93.43000031 93.11000061 92.37000275
 92.29000092 92.58000183 92.58999634 93.51000214 91.75       93.47000122
 92.75       93.41000366 93.19000244 92.76000214 93.04000092 93.37999725
 92.41999817 91.88999939]
[08/24 13:46:45] nl.defaults.predictor_evaluator INFO: [92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134
 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134
 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134
 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134
 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134
 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134
 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134
 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134
 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134
 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134
 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134
 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134
 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134
 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134
 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134
 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134
 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134
 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134
 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134
 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134
 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134
 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134
 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134
 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134
 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134 92.99134]
[08/24 13:46:45] nl.defaults.predictor_evaluator INFO: train_size: 500, fidelity: 5, kendall tau nan
[08/24 13:46:45] nl.defaults.predictor_evaluator INFO: mae: 0.4959, rmse: 0.6135, pearson: nan, spearman: nan, kendalltau: nan, kt_2dec: nan, kt_1dec: nan, precision_10: 0.0, precision_20: 0.0, train_size: 500, fidelity: 5, train_time: 3961623.352, fit_time: 102.462, query_time: 0.0001, hp_gcn_hidden: 144, hp_batch_size: 7, hp_lr: 0.0001, hp_wd: 0.0003, cv_score: 0, 
