[08/24 08:24:24] nl.utils.utils INFO: experiment_type....................vary_train_size
[08/24 08:24:24] nl.utils.utils INFO: search_space.................................darts
[08/24 08:24:24] nl.utils.utils INFO: dataset....................................cifar10
[08/24 08:24:24] nl.utils.utils INFO: predictor......................................gcn
[08/24 08:24:24] nl.utils.utils INFO: uniform_random...................................1
[08/24 08:24:24] nl.utils.utils INFO: test_size......................................200
[08/24 08:24:24] nl.utils.utils INFO: train_size_single...............................10
[08/24 08:24:24] nl.utils.utils INFO: train_size_list[5, 8, 12, 20, 31, 50, 79, 126, 199, 316, 500]
[08/24 08:24:24] nl.utils.utils INFO: fidelity_single..................................5
[08/24 08:24:24] nl.utils.utils INFO: fidelity_list[1, 2, 3, 4, 5, 7, 10, 13, 17, 23, 30, 40, 54, 71, 95]
[08/24 08:24:24] nl.utils.utils INFO: out_dir....................................p301_54
[08/24 08:24:24] nl.utils.utils INFO: max_hpo_time...................................900
[08/24 08:24:24] nl.utils.utils INFO: seed............................................56
[08/24 08:24:24] nl.utils.utils INFO: searchbatch_size: 256
cutout: False
cutout_length: 16
cutout_prob: 1.0
data_size: 25000
seed: 1000
train_portion: 0.7
[08/24 08:24:24] nl.utils.utils INFO: eval_only....................................False
[08/24 08:24:24] nl.utils.utils INFO: resume.......................................False
[08/24 08:24:24] nl.utils.utils INFO: model_path....................................None
[08/24 08:24:24] nl.utils.utils INFO: save.............p301_54/cifar10/predictors/gcn/56
[08/24 08:24:24] nl.utils.utils INFO: data............./home/zabergjg/NASLib/naslib/data
[08/24 08:24:24] nl.search_spaces.core.graph WARNING: Update function could not be veryfied. Be cautious with the setting of `private_edge_data` in `update_edges()`
[08/24 08:24:24] nl.search_spaces.core.graph WARNING: Update function could not be veryfied. Be cautious with the setting of `private_edge_data` in `update_edges()`
[08/24 08:24:24] nl.search_spaces.core.graph WARNING: Update function could not be veryfied. Be cautious with the setting of `private_edge_data` in `update_edges()`
[08/24 08:24:24] nl.search_spaces.core.graph WARNING: Update function could not be veryfied. Be cautious with the setting of `private_edge_data` in `update_edges()`
[08/24 08:24:24] nl.search_spaces.core.graph WARNING: Update function could not be veryfied. Be cautious with the setting of `private_edge_data` in `update_edges()`
[08/24 08:24:43] nl.defaults.predictor_evaluator INFO: Load the test set
[08/24 08:26:17] nl.defaults.predictor_evaluator INFO: Load the training set
[08/24 08:30:25] nl.defaults.predictor_evaluator INFO: Fit the predictor
[08/24 08:30:28] nl.defaults.predictor_evaluator INFO: Compute evaluation metrics
[08/24 08:30:28] nl.defaults.predictor_evaluator INFO: train_size: 5, fidelity: 5, kendall tau -0.0717
[08/24 08:30:28] nl.defaults.predictor_evaluator INFO: mae: 0.5478, rmse: 0.6923, pearson: 0.1068, spearman: -0.1053, kendalltau: -0.0717, kt_2dec: nan, kt_1dec: nan, precision_10: 0.0, precision_20: 0.0, train_size: 5, fidelity: 5, train_time: 35609.8954, fit_time: 2.7475, query_time: 0.0001, hp_gcn_hidden: 144, hp_batch_size: 7, hp_lr: 0.0001, hp_wd: 0.0003, cv_score: 0, 
[08/24 08:30:28] nl.defaults.predictor_evaluator INFO: Fit the predictor
[08/24 08:30:30] nl.defaults.predictor_evaluator INFO: Compute evaluation metrics
[08/24 08:30:30] nl.defaults.predictor_evaluator INFO: train_size: 8, fidelity: 5, kendall tau 0.3235
[08/24 08:30:30] nl.defaults.predictor_evaluator INFO: mae: 0.452, rmse: 0.5648, pearson: 0.4986, spearman: 0.4628, kendalltau: 0.3235, kt_2dec: 0.3245, kt_1dec: 0.3358, precision_10: 0.3, precision_20: 0.25, train_size: 8, fidelity: 5, train_time: 56422.4809, fit_time: 1.5072, query_time: 0.0001, hp_gcn_hidden: 144, hp_batch_size: 7, hp_lr: 0.0001, hp_wd: 0.0003, cv_score: 0, 
[08/24 08:30:30] nl.defaults.predictor_evaluator INFO: Fit the predictor
[08/24 08:30:31] nl.defaults.predictor_evaluator INFO: Compute evaluation metrics
[08/24 08:30:31] nl.defaults.predictor_evaluator INFO: train_size: 12, fidelity: 5, kendall tau 0.339
[08/24 08:30:31] nl.defaults.predictor_evaluator INFO: mae: 0.4772, rmse: 0.579, pearson: 0.5068, spearman: 0.4819, kendalltau: 0.339, kt_2dec: 0.3399, kt_1dec: 0.353, precision_10: 0.2, precision_20: 0.3, train_size: 12, fidelity: 5, train_time: 81221.5437, fit_time: 1.5032, query_time: 0.0001, hp_gcn_hidden: 144, hp_batch_size: 7, hp_lr: 0.0001, hp_wd: 0.0003, cv_score: 0, 
[08/24 08:30:31] nl.defaults.predictor_evaluator INFO: Fit the predictor
[08/24 08:30:34] nl.defaults.predictor_evaluator INFO: Compute evaluation metrics
[08/24 08:30:34] nl.defaults.predictor_evaluator INFO: train_size: 20, fidelity: 5, kendall tau 0.3074
[08/24 08:30:34] nl.defaults.predictor_evaluator INFO: mae: 0.5315, rmse: 0.6413, pearson: 0.4637, spearman: 0.443, kendalltau: 0.3074, kt_2dec: 0.3165, kt_1dec: 0.2176, precision_10: 0.2, precision_20: 0.25, train_size: 20, fidelity: 5, train_time: 142624.8528, fit_time: 2.9213, query_time: 0.0001, hp_gcn_hidden: 144, hp_batch_size: 7, hp_lr: 0.0001, hp_wd: 0.0003, cv_score: 0, 
[08/24 08:30:34] nl.defaults.predictor_evaluator INFO: Fit the predictor
[08/24 08:30:40] nl.defaults.predictor_evaluator INFO: Compute evaluation metrics
[08/24 08:30:40] nl.defaults.predictor_evaluator INFO: train_size: 31, fidelity: 5, kendall tau 0.3746
[08/24 08:30:40] nl.defaults.predictor_evaluator INFO: mae: 0.5219, rmse: 0.6337, pearson: 0.5552, spearman: 0.5293, kendalltau: 0.3746, kt_2dec: 0.4349, kt_1dec: nan, precision_10: 0.3, precision_20: 0.35, train_size: 31, fidelity: 5, train_time: 234581.0207, fit_time: 5.8144, query_time: 0.0001, hp_gcn_hidden: 144, hp_batch_size: 7, hp_lr: 0.0001, hp_wd: 0.0003, cv_score: 0, 
[08/24 08:30:40] nl.defaults.predictor_evaluator INFO: Fit the predictor
[08/24 08:30:50] nl.defaults.predictor_evaluator INFO: Compute evaluation metrics
[08/24 08:30:50] nl.defaults.predictor_evaluator INFO: train_size: 50, fidelity: 5, kendall tau 0.351
[08/24 08:30:50] nl.defaults.predictor_evaluator INFO: mae: 0.4613, rmse: 0.5611, pearson: 0.5242, spearman: 0.5042, kendalltau: 0.351, kt_2dec: 0.355, kt_1dec: 0.3499, precision_10: 0.2, precision_20: 0.3, train_size: 50, fidelity: 5, train_time: 380604.1157, fit_time: 10.0986, query_time: 0.0001, hp_gcn_hidden: 144, hp_batch_size: 7, hp_lr: 0.0001, hp_wd: 0.0003, cv_score: 0, 
[08/24 08:30:50] nl.defaults.predictor_evaluator INFO: Fit the predictor
[08/24 08:31:06] nl.defaults.predictor_evaluator INFO: Compute evaluation metrics
[08/24 08:31:06] nl.defaults.predictor_evaluator INFO: train_size: 79, fidelity: 5, kendall tau 0.4212
[08/24 08:31:06] nl.defaults.predictor_evaluator INFO: mae: 0.524, rmse: 0.6342, pearson: 0.5943, spearman: 0.5854, kendalltau: 0.4212, kt_2dec: 0.4192, kt_1dec: nan, precision_10: 0.4, precision_20: 0.4, train_size: 79, fidelity: 5, train_time: 612114.787, fit_time: 15.7983, query_time: 0.0001, hp_gcn_hidden: 144, hp_batch_size: 7, hp_lr: 0.0001, hp_wd: 0.0003, cv_score: 0, 
[08/24 08:31:06] nl.defaults.predictor_evaluator INFO: Fit the predictor
[08/24 08:31:32] nl.defaults.predictor_evaluator INFO: Compute evaluation metrics
[08/24 08:31:32] nl.defaults.predictor_evaluator INFO: Error when computing metrics. ytest and test_pred are:
[08/24 08:31:32] nl.defaults.predictor_evaluator INFO: [92.81999969 93.51999664 93.44000244 92.04000092 93.41999817 92.66000366
 92.69999695 92.15000153 92.95999908 93.05999756 93.37000275 93.73000336
 93.12000275 92.87999725 92.81999969 93.51999664 93.45999908 93.31999969
 92.97000122 92.65000153 92.84999847 93.65000153 92.25       92.27999878
 93.38999939 93.41999817 93.15000153 93.13999939 93.87999725 93.73000336
 93.44000244 93.83000183 93.23999786 92.43000031 93.06999969 92.83999634
 93.87000275 92.25       92.97000122 93.51000214 93.41000366 92.25
 93.16000366 93.62000275 92.98999786 92.56999969 91.51999664 93.05999756
 93.62000275 93.83999634 93.58000183 93.36000061 93.20999908 93.29000092
 94.13999939 93.73999786 91.30000305 91.36000061 92.26999664 92.65000153
 92.43000031 92.26000214 93.59999847 92.25       93.80000305 93.05999756
 93.33000183 93.29000092 92.5        93.05999756 92.56999969 92.76999664
 93.73000336 93.66000366 92.51000214 93.40000153 92.88999939 93.11000061
 92.23999786 92.95999908 93.80999756 92.75       93.66000366 93.66000366
 92.98999786 92.51999664 94.05000305 92.75       92.26000214 93.18000031
 93.66000366 91.83999634 92.43000031 92.65000153 93.04000092 92.48999786
 92.95999908 92.51999664 93.27999878 92.94999695 92.22000122 91.97000122
 92.38999939 94.01999664 93.79000092 91.63999939 93.88999939 93.16000366
 92.91000366 93.19000244 92.68000031 91.90000153 92.38999939 94.29000092
 91.59999847 93.55000305 92.73000336 93.41000366 92.5        92.98999786
 94.12999725 93.23999786 92.05000305 92.25       94.08999634 92.05999756
 92.51000214 92.54000092 93.55999756 93.27999878 93.23999786 93.51000214
 93.76000214 92.30000305 93.55000305 91.41999817 93.38999939 93.83000183
 93.83999634 93.04000092 93.62000275 92.76000214 93.11000061 91.94999695
 92.12999725 92.68000031 91.84999847 93.79000092 93.02999878 93.06999969
 93.66000366 92.94000244 93.87999725 92.33000183 92.77999878 93.04000092
 93.22000122 92.91999817 92.66000366 92.83000183 93.68000031 93.16999817
 93.27999878 93.04000092 92.98000336 93.75       93.23999786 93.76999664
 92.65000153 92.56999969 94.30000305 93.25       93.26000214 93.48000336
 92.87999725 92.40000153 93.23999786 92.31999969 92.         93.73000336
 92.48000336 92.58999634 93.65000153 92.62999725 93.83999634 91.55000305
 92.56999969 91.86000061 93.36000061 92.16999817 93.09999847 93.16000366
 93.93000031 93.05000305 92.81999969 92.38999939 92.59999847 92.86000061
 93.09999847 93.23000336]
[08/24 08:31:32] nl.defaults.predictor_evaluator INFO: [92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691
 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691
 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691
 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691
 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691
 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691
 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691
 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691
 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691
 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691
 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691
 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691
 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691
 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691
 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691
 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691
 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691
 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691
 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691
 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691
 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691
 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691
 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691
 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691
 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691 92.84691]
[08/24 08:31:32] nl.defaults.predictor_evaluator INFO: train_size: 126, fidelity: 5, kendall tau nan
[08/24 08:31:32] nl.defaults.predictor_evaluator INFO: mae: 0.5355, rmse: 0.6463, pearson: nan, spearman: nan, kendalltau: nan, kt_2dec: nan, kt_1dec: nan, precision_10: 0.0, precision_20: 0.0, train_size: 126, fidelity: 5, train_time: 974728.6803, fit_time: 25.4616, query_time: 0.0001, hp_gcn_hidden: 144, hp_batch_size: 7, hp_lr: 0.0001, hp_wd: 0.0003, cv_score: 0, 
[08/24 08:31:32] nl.defaults.predictor_evaluator INFO: Fit the predictor
[08/24 08:32:11] nl.defaults.predictor_evaluator INFO: Compute evaluation metrics
[08/24 08:32:11] nl.defaults.predictor_evaluator INFO: train_size: 199, fidelity: 5, kendall tau 0.4792
[08/24 08:32:11] nl.defaults.predictor_evaluator INFO: mae: 0.3803, rmse: 0.4899, pearson: 0.6548, spearman: 0.6565, kendalltau: 0.4792, kt_2dec: 0.4805, kt_1dec: 0.4875, precision_10: 0.5, precision_20: 0.4, train_size: 199, fidelity: 5, train_time: 1556342.3644, fit_time: 39.5843, query_time: 0.0001, hp_gcn_hidden: 144, hp_batch_size: 7, hp_lr: 0.0001, hp_wd: 0.0003, cv_score: 0, 
[08/24 08:32:11] nl.defaults.predictor_evaluator INFO: Fit the predictor
[08/24 08:33:15] nl.defaults.predictor_evaluator INFO: Compute evaluation metrics
[08/24 08:33:15] nl.defaults.predictor_evaluator INFO: train_size: 316, fidelity: 5, kendall tau 0.5203
[08/24 08:33:15] nl.defaults.predictor_evaluator INFO: mae: 0.3478, rmse: 0.4515, pearson: 0.7071, spearman: 0.7024, kendalltau: 0.5203, kt_2dec: 0.523, kt_1dec: 0.5385, precision_10: 0.4, precision_20: 0.45, train_size: 316, fidelity: 5, train_time: 2481374.9952, fit_time: 63.6014, query_time: 0.0001, hp_gcn_hidden: 144, hp_batch_size: 7, hp_lr: 0.0001, hp_wd: 0.0003, cv_score: 0, 
[08/24 08:33:15] nl.defaults.predictor_evaluator INFO: Fit the predictor
[08/24 08:34:57] nl.defaults.predictor_evaluator INFO: Compute evaluation metrics
[08/24 08:34:57] nl.defaults.predictor_evaluator INFO: Error when computing metrics. ytest and test_pred are:
[08/24 08:34:57] nl.defaults.predictor_evaluator INFO: [92.81999969 93.51999664 93.44000244 92.04000092 93.41999817 92.66000366
 92.69999695 92.15000153 92.95999908 93.05999756 93.37000275 93.73000336
 93.12000275 92.87999725 92.81999969 93.51999664 93.45999908 93.31999969
 92.97000122 92.65000153 92.84999847 93.65000153 92.25       92.27999878
 93.38999939 93.41999817 93.15000153 93.13999939 93.87999725 93.73000336
 93.44000244 93.83000183 93.23999786 92.43000031 93.06999969 92.83999634
 93.87000275 92.25       92.97000122 93.51000214 93.41000366 92.25
 93.16000366 93.62000275 92.98999786 92.56999969 91.51999664 93.05999756
 93.62000275 93.83999634 93.58000183 93.36000061 93.20999908 93.29000092
 94.13999939 93.73999786 91.30000305 91.36000061 92.26999664 92.65000153
 92.43000031 92.26000214 93.59999847 92.25       93.80000305 93.05999756
 93.33000183 93.29000092 92.5        93.05999756 92.56999969 92.76999664
 93.73000336 93.66000366 92.51000214 93.40000153 92.88999939 93.11000061
 92.23999786 92.95999908 93.80999756 92.75       93.66000366 93.66000366
 92.98999786 92.51999664 94.05000305 92.75       92.26000214 93.18000031
 93.66000366 91.83999634 92.43000031 92.65000153 93.04000092 92.48999786
 92.95999908 92.51999664 93.27999878 92.94999695 92.22000122 91.97000122
 92.38999939 94.01999664 93.79000092 91.63999939 93.88999939 93.16000366
 92.91000366 93.19000244 92.68000031 91.90000153 92.38999939 94.29000092
 91.59999847 93.55000305 92.73000336 93.41000366 92.5        92.98999786
 94.12999725 93.23999786 92.05000305 92.25       94.08999634 92.05999756
 92.51000214 92.54000092 93.55999756 93.27999878 93.23999786 93.51000214
 93.76000214 92.30000305 93.55000305 91.41999817 93.38999939 93.83000183
 93.83999634 93.04000092 93.62000275 92.76000214 93.11000061 91.94999695
 92.12999725 92.68000031 91.84999847 93.79000092 93.02999878 93.06999969
 93.66000366 92.94000244 93.87999725 92.33000183 92.77999878 93.04000092
 93.22000122 92.91999817 92.66000366 92.83000183 93.68000031 93.16999817
 93.27999878 93.04000092 92.98000336 93.75       93.23999786 93.76999664
 92.65000153 92.56999969 94.30000305 93.25       93.26000214 93.48000336
 92.87999725 92.40000153 93.23999786 92.31999969 92.         93.73000336
 92.48000336 92.58999634 93.65000153 92.62999725 93.83999634 91.55000305
 92.56999969 91.86000061 93.36000061 92.16999817 93.09999847 93.16000366
 93.93000031 93.05000305 92.81999969 92.38999939 92.59999847 92.86000061
 93.09999847 93.23000336]
[08/24 08:34:57] nl.defaults.predictor_evaluator INFO: [92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372
 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372
 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372
 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372
 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372
 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372
 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372
 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372
 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372
 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372
 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372
 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372
 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372
 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372
 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372
 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372
 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372
 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372
 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372
 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372
 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372
 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372
 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372
 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372
 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372 92.92372]
[08/24 08:34:57] nl.defaults.predictor_evaluator INFO: train_size: 500, fidelity: 5, kendall tau nan
[08/24 08:34:57] nl.defaults.predictor_evaluator INFO: mae: 0.5206, rmse: 0.6333, pearson: nan, spearman: nan, kendalltau: nan, kt_2dec: nan, kt_1dec: nan, precision_10: 0.0, precision_20: 0.0, train_size: 500, fidelity: 5, train_time: 3938089.0021, fit_time: 102.5073, query_time: 0.0001, hp_gcn_hidden: 144, hp_batch_size: 7, hp_lr: 0.0001, hp_wd: 0.0003, cv_score: 0, 
