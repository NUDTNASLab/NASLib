[08/26 04:57:30] nl.utils.utils INFO: experiment_type....................vary_train_size
[08/26 04:57:30] nl.utils.utils INFO: search_space.................................darts
[08/26 04:57:30] nl.utils.utils INFO: dataset....................................cifar10
[08/26 04:57:30] nl.utils.utils INFO: predictor......................................gcn
[08/26 04:57:30] nl.utils.utils INFO: uniform_random...................................1
[08/26 04:57:30] nl.utils.utils INFO: test_size......................................200
[08/26 04:57:30] nl.utils.utils INFO: train_size_single...............................10
[08/26 04:57:30] nl.utils.utils INFO: train_size_list[5, 8, 12, 20, 31, 50, 79, 126, 199, 316, 500]
[08/26 04:57:30] nl.utils.utils INFO: fidelity_single..................................5
[08/26 04:57:30] nl.utils.utils INFO: fidelity_list[1, 2, 3, 4, 5, 7, 10, 13, 17, 23, 30, 40, 54, 71, 95]
[08/26 04:57:30] nl.utils.utils INFO: out_dir....................................p301_20
[08/26 04:57:30] nl.utils.utils INFO: max_hpo_time...................................900
[08/26 04:57:30] nl.utils.utils INFO: seed............................................20
[08/26 04:57:30] nl.utils.utils INFO: searchbatch_size: 256
cutout: False
cutout_length: 16
cutout_prob: 1.0
data_size: 25000
seed: 1000
train_portion: 0.7
[08/26 04:57:30] nl.utils.utils INFO: eval_only....................................False
[08/26 04:57:30] nl.utils.utils INFO: resume.......................................False
[08/26 04:57:30] nl.utils.utils INFO: model_path....................................None
[08/26 04:57:30] nl.utils.utils INFO: save.............p301_20/cifar10/predictors/gcn/20
[08/26 04:57:30] nl.utils.utils INFO: data.............../home/shalag/NASLib/naslib/data
[08/26 04:57:30] nl.search_spaces.core.graph WARNING: Update function could not be veryfied. Be cautious with the setting of `private_edge_data` in `update_edges()`
[08/26 04:57:30] nl.search_spaces.core.graph WARNING: Update function could not be veryfied. Be cautious with the setting of `private_edge_data` in `update_edges()`
[08/26 04:57:30] nl.search_spaces.core.graph WARNING: Update function could not be veryfied. Be cautious with the setting of `private_edge_data` in `update_edges()`
[08/26 04:57:30] nl.search_spaces.core.graph WARNING: Update function could not be veryfied. Be cautious with the setting of `private_edge_data` in `update_edges()`
[08/26 04:57:30] nl.search_spaces.core.graph WARNING: Update function could not be veryfied. Be cautious with the setting of `private_edge_data` in `update_edges()`
[08/26 04:57:49] nl.defaults.predictor_evaluator INFO: Load the test set
[08/26 04:59:20] nl.defaults.predictor_evaluator INFO: Load the training set
[08/26 05:03:18] nl.defaults.predictor_evaluator INFO: Fit the predictor
[08/26 05:03:22] nl.defaults.predictor_evaluator INFO: Compute evaluation metrics
[08/26 05:03:22] nl.defaults.predictor_evaluator INFO: train_size: 5, fidelity: 5, kendall tau 0.3392
[08/26 05:03:22] nl.defaults.predictor_evaluator INFO: mae: 0.5277, rmse: 0.6706, pearson: 0.4962, spearman: 0.4811, kendalltau: 0.3392, kt_2dec: nan, kt_1dec: nan, precision_10: 0.1, precision_20: 0.45, train_size: 5, fidelity: 5, train_time: 34780.7248, fit_time: 3.7104, query_time: 0.0001, hp_gcn_hidden: 144, hp_batch_size: 7, hp_lr: 0.0001, hp_wd: 0.0003, cv_score: 0, 
[08/26 05:03:22] nl.defaults.predictor_evaluator INFO: Fit the predictor
[08/26 05:03:23] nl.defaults.predictor_evaluator INFO: Compute evaluation metrics
[08/26 05:03:23] nl.defaults.predictor_evaluator INFO: train_size: 8, fidelity: 5, kendall tau 0.1691
[08/26 05:03:23] nl.defaults.predictor_evaluator INFO: mae: 0.6418, rmse: 0.7748, pearson: 0.2559, spearman: 0.2419, kendalltau: 0.1691, kt_2dec: 0.17, kt_1dec: 0.1652, precision_10: 0.0, precision_20: 0.15, train_size: 8, fidelity: 5, train_time: 58891.8636, fit_time: 1.6557, query_time: 0.0001, hp_gcn_hidden: 144, hp_batch_size: 7, hp_lr: 0.0001, hp_wd: 0.0003, cv_score: 0, 
[08/26 05:03:23] nl.defaults.predictor_evaluator INFO: Fit the predictor
[08/26 05:03:25] nl.defaults.predictor_evaluator INFO: Compute evaluation metrics
[08/26 05:03:25] nl.defaults.predictor_evaluator INFO: train_size: 12, fidelity: 5, kendall tau 0.2529
[08/26 05:03:25] nl.defaults.predictor_evaluator INFO: mae: 0.5497, rmse: 0.6704, pearson: 0.3452, spearman: 0.3626, kendalltau: 0.2529, kt_2dec: 0.2531, kt_1dec: 0.2586, precision_10: 0.1, precision_20: 0.15, train_size: 12, fidelity: 5, train_time: 91151.624, fit_time: 1.6588, query_time: 0.0001, hp_gcn_hidden: 144, hp_batch_size: 7, hp_lr: 0.0001, hp_wd: 0.0003, cv_score: 0, 
[08/26 05:03:25] nl.defaults.predictor_evaluator INFO: Fit the predictor
[08/26 05:03:28] nl.defaults.predictor_evaluator INFO: Compute evaluation metrics
[08/26 05:03:28] nl.defaults.predictor_evaluator INFO: train_size: 20, fidelity: 5, kendall tau 0.2465
[08/26 05:03:28] nl.defaults.predictor_evaluator INFO: mae: 0.5456, rmse: 0.6739, pearson: 0.4321, spearman: 0.356, kendalltau: 0.2465, kt_2dec: 0.2575, kt_1dec: 0.2589, precision_10: 0.3, precision_20: 0.3, train_size: 20, fidelity: 5, train_time: 155154.0473, fit_time: 3.2663, query_time: 0.0001, hp_gcn_hidden: 144, hp_batch_size: 7, hp_lr: 0.0001, hp_wd: 0.0003, cv_score: 0, 
[08/26 05:03:28] nl.defaults.predictor_evaluator INFO: Fit the predictor
[08/26 05:03:35] nl.defaults.predictor_evaluator INFO: Compute evaluation metrics
[08/26 05:03:35] nl.defaults.predictor_evaluator INFO: train_size: 31, fidelity: 5, kendall tau 0.317
[08/26 05:03:35] nl.defaults.predictor_evaluator INFO: mae: 0.5366, rmse: 0.6752, pearson: 0.5169, spearman: 0.4549, kendalltau: 0.317, kt_2dec: nan, kt_1dec: nan, precision_10: 0.0, precision_20: 0.3, train_size: 31, fidelity: 5, train_time: 237567.2503, fit_time: 6.4331, query_time: 0.0001, hp_gcn_hidden: 144, hp_batch_size: 7, hp_lr: 0.0001, hp_wd: 0.0003, cv_score: 0, 
[08/26 05:03:35] nl.defaults.predictor_evaluator INFO: Fit the predictor
[08/26 05:03:46] nl.defaults.predictor_evaluator INFO: Compute evaluation metrics
[08/26 05:03:46] nl.defaults.predictor_evaluator INFO: train_size: 50, fidelity: 5, kendall tau 0.3924
[08/26 05:03:46] nl.defaults.predictor_evaluator INFO: mae: 0.4244, rmse: 0.5378, pearson: 0.6047, spearman: 0.5515, kendalltau: 0.3924, kt_2dec: 0.3944, kt_1dec: 0.411, precision_10: 0.3, precision_20: 0.35, train_size: 50, fidelity: 5, train_time: 393223.9678, fit_time: 11.2226, query_time: 0.0001, hp_gcn_hidden: 144, hp_batch_size: 7, hp_lr: 0.0001, hp_wd: 0.0003, cv_score: 0, 
[08/26 05:03:46] nl.defaults.predictor_evaluator INFO: Fit the predictor
[08/26 05:04:03] nl.defaults.predictor_evaluator INFO: Compute evaluation metrics
[08/26 05:04:03] nl.defaults.predictor_evaluator INFO: train_size: 79, fidelity: 5, kendall tau 0.4003
[08/26 05:04:03] nl.defaults.predictor_evaluator INFO: mae: 0.4553, rmse: 0.5909, pearson: 0.5522, spearman: 0.5595, kendalltau: 0.4003, kt_2dec: 0.4012, kt_1dec: 0.4135, precision_10: 0.2, precision_20: 0.35, train_size: 79, fidelity: 5, train_time: 619897.7553, fit_time: 17.1339, query_time: 0.0001, hp_gcn_hidden: 144, hp_batch_size: 7, hp_lr: 0.0001, hp_wd: 0.0003, cv_score: 0, 
[08/26 05:04:03] nl.defaults.predictor_evaluator INFO: Fit the predictor
[08/26 05:04:32] nl.defaults.predictor_evaluator INFO: Compute evaluation metrics
[08/26 05:04:32] nl.defaults.predictor_evaluator INFO: train_size: 126, fidelity: 5, kendall tau 0.4169
[08/26 05:04:32] nl.defaults.predictor_evaluator INFO: mae: 0.4008, rmse: 0.5211, pearson: 0.6362, spearman: 0.5824, kendalltau: 0.4169, kt_2dec: 0.4172, kt_1dec: 0.4331, precision_10: 0.3, precision_20: 0.45, train_size: 126, fidelity: 5, train_time: 992440.822, fit_time: 28.7047, query_time: 0.0001, hp_gcn_hidden: 144, hp_batch_size: 7, hp_lr: 0.0001, hp_wd: 0.0003, cv_score: 0, 
[08/26 05:04:32] nl.defaults.predictor_evaluator INFO: Fit the predictor
[08/26 05:05:17] nl.defaults.predictor_evaluator INFO: Compute evaluation metrics
[08/26 05:05:17] nl.defaults.predictor_evaluator INFO: Error when computing metrics. ytest and test_pred are:
[08/26 05:05:17] nl.defaults.predictor_evaluator INFO: [93.44000244 91.87999725 93.36000061 93.12999725 93.01000214 93.06999969
 91.33000183 93.5        92.83000183 93.44000244 93.66999817 93.23000336
 92.87999725 93.01999664 92.76000214 93.59999847 93.15000153 92.73000336
 92.73000336 92.54000092 93.37000275 92.47000122 92.91000366 93.47000122
 93.37000275 93.80999756 92.65000153 93.59999847 92.38999939 91.47000122
 92.19999695 93.12000275 92.11000061 93.06999969 93.01000214 91.55000305
 93.22000122 93.93000031 92.04000092 92.11000061 93.16999817 92.70999908
 92.19000244 92.59999847 92.41000366 92.68000031 92.12000275 93.12999725
 93.86000061 93.04000092 93.04000092 92.79000092 91.56999969 93.30000305
 92.97000122 92.61000061 93.08000183 93.84999847 92.31999969 93.55999756
 93.80000305 93.33000183 93.55000305 92.33000183 94.01000214 93.62000275
 92.41000366 92.52999878 92.76999664 92.19000244 93.16000366 93.41000366
 92.76999664 93.44000244 93.04000092 92.69999695 92.47000122 93.08999634
 94.29000092 93.80999756 93.76000214 93.54000092 92.62000275 92.44000244
 93.31999969 92.47000122 92.73999786 93.51999664 93.80000305 93.41000366
 92.45999908 93.80000305 92.04000092 91.90000153 93.41999817 93.31999969
 93.62000275 93.41000366 93.05999756 93.80999756 92.87999725 93.68000031
 93.31999969 94.29000092 93.83999634 93.62999725 93.34999847 92.76999664
 92.25       92.34999847 93.22000122 93.36000061 93.58999634 92.83000183
 92.34999847 92.06999969 92.12000275 92.91999817 93.83999634 93.48000336
 92.70999908 93.69000244 93.18000031 92.94000244 93.23999786 92.43000031
 93.23999786 92.86000061 92.91999817 93.30000305 92.12999725 93.25
 93.51000214 92.58999634 92.47000122 92.87999725 92.91000366 92.5
 93.61000061 93.83999634 94.12000275 93.63999939 92.63999939 93.30999756
 93.20999908 93.45999908 91.40000153 93.25       93.12000275 93.45999908
 93.38999939 93.80999756 92.90000153 92.77999878 91.48999786 93.01000214
 93.93000031 92.93000031 91.41000366 93.20999908 92.68000031 92.87000275
 93.51999664 91.94999695 93.77999878 91.98000336 92.30999756 92.19999695
 92.76000214 93.41000366 93.34999847 92.54000092 93.5        93.06999969
 90.08000183 92.94000244 93.59999847 93.12999725 92.76000214 93.01000214
 93.77999878 91.84999847 93.20999908 93.79000092 93.51000214 90.51000214
 93.31999969 92.84999847 93.66999817 92.93000031 93.36000061 92.26000214
 94.         93.59999847 93.01999664 93.30000305 93.30000305 93.37000275
 91.79000092 93.37000275]
[08/26 05:05:17] nl.defaults.predictor_evaluator INFO: [92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331
 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331
 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331
 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331
 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331
 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331
 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331
 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331
 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331
 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331
 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331
 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331
 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331
 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331
 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331
 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331
 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331
 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331
 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331
 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331
 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331
 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331
 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331
 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331
 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331 92.94331]
[08/26 05:05:17] nl.defaults.predictor_evaluator INFO: train_size: 199, fidelity: 5, kendall tau nan
[08/26 05:05:17] nl.defaults.predictor_evaluator INFO: mae: 0.5282, rmse: 0.6709, pearson: nan, spearman: nan, kendalltau: nan, kt_2dec: nan, kt_1dec: nan, precision_10: 0.0, precision_20: 0.0, train_size: 199, fidelity: 5, train_time: 1580205.6152, fit_time: 44.663, query_time: 0.0001, hp_gcn_hidden: 144, hp_batch_size: 7, hp_lr: 0.0001, hp_wd: 0.0003, cv_score: 0, 
[08/26 05:05:17] nl.defaults.predictor_evaluator INFO: Fit the predictor
[08/26 05:06:28] nl.defaults.predictor_evaluator INFO: Compute evaluation metrics
[08/26 05:06:28] nl.defaults.predictor_evaluator INFO: train_size: 316, fidelity: 5, kendall tau 0.5096
[08/26 05:06:28] nl.defaults.predictor_evaluator INFO: mae: 0.3678, rmse: 0.4715, pearson: 0.7157, spearman: 0.6937, kendalltau: 0.5096, kt_2dec: 0.5098, kt_1dec: 0.527, precision_10: 0.5, precision_20: 0.5, train_size: 316, fidelity: 5, train_time: 2512470.0664, fit_time: 71.4654, query_time: 0.0001, hp_gcn_hidden: 144, hp_batch_size: 7, hp_lr: 0.0001, hp_wd: 0.0003, cv_score: 0, 
[08/26 05:06:28] nl.defaults.predictor_evaluator INFO: Fit the predictor
[08/26 05:08:22] nl.defaults.predictor_evaluator INFO: Compute evaluation metrics
[08/26 05:08:22] nl.defaults.predictor_evaluator INFO: train_size: 500, fidelity: 5, kendall tau 0.5575
[08/26 05:08:22] nl.defaults.predictor_evaluator INFO: mae: 0.3418, rmse: 0.4292, pearson: 0.7703, spearman: 0.7522, kendalltau: 0.5575, kt_2dec: 0.5591, kt_1dec: 0.5712, precision_10: 0.4, precision_20: 0.6, train_size: 500, fidelity: 5, train_time: 3979637.24, fit_time: 113.7186, query_time: 0.0001, hp_gcn_hidden: 144, hp_batch_size: 7, hp_lr: 0.0001, hp_wd: 0.0003, cv_score: 0, 
