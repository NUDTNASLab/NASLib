[{"experiment_type":"vary_train_size","search_space":"darts","dataset":"cifar10","predictor":"gp","uniform_random":1,"test_size":200,"train_size_single":10,"train_size_list":[5,8,12,20,31,50,79,126,199,316,500],"fidelity_single":5,"fidelity_list":[1,2,3,4,5,7,10,13,17,23,30,40,54,71,95],"out_dir":"p301_20","max_hpo_time":900,"seed":20,"search":{"seed":1000,"batch_size":256,"data_size":25000,"cutout":false,"cutout_length":16,"cutout_prob":1.0,"train_portion":0.7},"eval_only":false,"resume":false,"model_path":null,"save":"p301_20/cifar10/predictors/gp/20","data":"/home/shalag/NASLib/naslib/data"},{"mae":0.5281299591064453,"rmse":0.6708514526158473,"pearson":NaN,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":5,"fidelity":5,"train_time":34780.724762,"fit_time":0.003802776336669922,"query_time":5.349278450012207e-05,"cv_score":0},{"mae":0.5479287735770412,"rmse":0.6825144970390711,"pearson":0.015760647402763492,"spearman":0.10994576310916387,"kendalltau":0.0751924217128392,"kt_2dec":0.020967207257665786,"kt_1dec":0.02430172438024599,"precision_10":0.3,"precision_20":0.25,"train_size":8,"fidelity":5,"train_time":58891.863618999996,"fit_time":0.0024106502532958984,"query_time":5.002140998840332e-05,"cv_score":0},{"mae":0.5462499046325671,"rmse":0.68139366013501,"pearson":5.940840427075312e-15,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":12,"fidelity":5,"train_time":91151.624002,"fit_time":0.002385377883911133,"query_time":9.397268295288085e-05,"cv_score":0},{"mae":0.5445699157714858,"rmse":0.6802576885189031,"pearson":NaN,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":20,"fidelity":5,"train_time":155154.047276,"fit_time":0.002857685089111328,"query_time":5.234479904174805e-05,"cv_score":0},{"mae":0.5367725938362876,"rmse":0.6752941295529373,"pearson":0.04637030531817304,"spearman":0.17321784889693193,"kendalltau":0.13836051162674742,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.3,"precision_20":0.3,"train_size":31,"fidelity":5,"train_time":237567.25028599997,"fit_time":0.0032639503479003906,"query_time":5.266070365905762e-05,"cv_score":0},{"mae":0.5345900695800778,"rmse":0.6740696578969462,"pearson":5.940840427075312e-15,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":50,"fidelity":5,"train_time":393223.96779900003,"fit_time":0.013846158981323242,"query_time":8.79514217376709e-05,"cv_score":0},{"mae":0.5424336020554162,"rmse":0.6788612201097104,"pearson":NaN,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":79,"fidelity":5,"train_time":619897.7552820002,"fit_time":0.013659000396728516,"query_time":8.4000825881958e-05,"cv_score":0},{"mae":0.5359294013689062,"rmse":0.6747054919847185,"pearson":0.06900115938162582,"spearman":0.17942161703668508,"kendalltau":0.13904511533617533,"kt_2dec":0.06903877520667823,"kt_1dec":0.06903877520667823,"precision_10":0.2,"precision_20":0.25,"train_size":126,"fidelity":5,"train_time":992440.821987,"fit_time":0.007851600646972656,"query_time":5.3007602691650394e-05,"cv_score":0},{"mae":0.49340654713158627,"rmse":0.6367574136271809,"pearson":0.38305582657824316,"spearman":0.3823492135424195,"kendalltau":0.2658949175314609,"kt_2dec":0.2694131418293969,"kt_1dec":0.29427348005755544,"precision_10":0.4,"precision_20":0.45,"train_size":199,"fidelity":5,"train_time":1580205.615229,"fit_time":0.011977672576904297,"query_time":5.742073059082031e-05,"cv_score":0},{"mae":0.4924324713188321,"rmse":0.6270249671177326,"pearson":0.39628256433312875,"spearman":0.3709587538776874,"kendalltau":0.2571258281359957,"kt_2dec":0.259278529955758,"kt_1dec":0.26858528084945626,"precision_10":0.2,"precision_20":0.4,"train_size":316,"fidelity":5,"train_time":2512470.066399,"fit_time":0.018761157989501953,"query_time":6.169438362121582e-05,"cv_score":0},{"mae":0.5179096732173453,"rmse":0.6626663355423889,"pearson":0.18844196734816654,"spearman":0.19004905765633537,"kendalltau":0.15747385707210274,"kt_2dec":0.15747385707210274,"kt_1dec":0.16341932304906787,"precision_10":0.0,"precision_20":0.0,"train_size":500,"fidelity":5,"train_time":3979637.240011,"fit_time":0.03446626663208008,"query_time":7.479310035705566e-05,"cv_score":0}]