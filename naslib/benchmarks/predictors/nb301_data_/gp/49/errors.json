[{"experiment_type":"vary_train_size","search_space":"darts","dataset":"cifar10","predictor":"gp","uniform_random":1,"test_size":200,"train_size_single":10,"train_size_list":[5,8,12,20,31,50,79,126,199,316,500],"fidelity_single":5,"fidelity_list":[1,2,3,4,5,7,10,13,17,23,30,40,54,71,95],"out_dir":"p301_40","max_hpo_time":900,"seed":49,"search":{"seed":1000,"batch_size":256,"data_size":25000,"cutout":false,"cutout_length":16,"cutout_prob":1.0,"train_portion":0.7},"eval_only":false,"resume":false,"model_path":null,"save":"p301_40/cifar10/predictors/gp/49","data":"/home/shalag/NASLib/naslib/data"},{"mae":0.5532899932861323,"rmse":0.7264607583702171,"pearson":5.496292648869126e-15,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":5,"fidelity":5,"train_time":38073.55801200001,"fit_time":0.003778219223022461,"query_time":5.5003166198730466e-05,"cv_score":0},{"mae":0.5336000536410731,"rmse":0.745666888138529,"pearson":0.014316551995844183,"spearman":0.02162936307863645,"kendalltau":0.0161071317600043,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.05,"train_size":8,"fidelity":5,"train_time":59610.473658999996,"fit_time":0.0022644996643066406,"query_time":4.982948303222656e-05,"cv_score":0},{"mae":0.5334833844502767,"rmse":0.7429580208883999,"pearson":5.496292648869126e-15,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":12,"fidelity":5,"train_time":89046.125077,"fit_time":0.002359628677368164,"query_time":6.53839111328125e-05,"cv_score":0},{"mae":0.5400075679593537,"rmse":0.7234191730414694,"pearson":0.17243827620636812,"spearman":0.2156450805902288,"kendalltau":0.14612440372877922,"kt_2dec":0.20726322958509397,"kt_1dec":0.16668792329151802,"precision_10":0.1,"precision_20":0.15,"train_size":20,"fidelity":5,"train_time":149929.925813,"fit_time":0.002805948257446289,"query_time":4.985928535461426e-05,"cv_score":0},{"mae":0.5468435693556256,"rmse":0.7243292696394126,"pearson":NaN,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":31,"fidelity":5,"train_time":233693.32396300006,"fit_time":0.003320455551147461,"query_time":8.042573928833007e-05,"cv_score":0},{"mae":0.5381408386006604,"rmse":0.7188230875378165,"pearson":0.43243470982815974,"spearman":0.4574610520556193,"kendalltau":0.3216147252010532,"kt_2dec":0.3107191210035745,"kt_1dec":0.232673331973538,"precision_10":0.3,"precision_20":0.35,"train_size":50,"fidelity":5,"train_time":388493.00688,"fit_time":0.014051198959350586,"query_time":8.366227149963378e-05,"cv_score":0},{"mae":0.5399424086944962,"rmse":0.7245340192255755,"pearson":NaN,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":79,"fidelity":5,"train_time":619974.543331,"fit_time":0.01523447036743164,"query_time":8.618354797363282e-05,"cv_score":0},{"mae":0.5462027291740849,"rmse":0.7242152333423822,"pearson":0.005519016934918823,"spearman":0.32538500344580196,"kendalltau":0.22300077441030108,"kt_2dec":0.02014763629303326,"kt_1dec":NaN,"precision_10":0.1,"precision_20":0.25,"train_size":126,"fidelity":5,"train_time":987367.688872,"fit_time":0.007826566696166992,"query_time":5.42449951171875e-05,"cv_score":0},{"mae":0.542943892812595,"rmse":0.7239426949458008,"pearson":0.008285351451478013,"spearman":0.01125899877209716,"kendalltau":0.008915288560156904,"kt_2dec":0.008915288560156904,"kt_1dec":-0.007051672702561642,"precision_10":0.0,"precision_20":0.0,"train_size":199,"fidelity":5,"train_time":1590391.702647,"fit_time":0.01223301887512207,"query_time":5.9734582901000974e-05,"cv_score":0},{"mae":0.5425873903637459,"rmse":0.7237660268760974,"pearson":0.0285794445654071,"spearman":0.0450214311443449,"kendalltau":0.03662747773471056,"kt_2dec":0.03662747773471056,"kt_1dec":0.022109915629189122,"precision_10":0.0,"precision_20":0.0,"train_size":316,"fidelity":5,"train_time":2519210.084838,"fit_time":0.02170109748840332,"query_time":6.637930870056153e-05,"cv_score":0},{"mae":0.5382559054143972,"rmse":0.7232930025649563,"pearson":0.05631224289372982,"spearman":0.07306384965087588,"kendalltau":0.05964998771349947,"kt_2dec":0.05964998771349947,"kt_1dec":0.043965864815983434,"precision_10":0.0,"precision_20":0.0,"train_size":500,"fidelity":5,"train_time":3987100.770091,"fit_time":0.033050537109375,"query_time":8.246064186096192e-05,"cv_score":0}]