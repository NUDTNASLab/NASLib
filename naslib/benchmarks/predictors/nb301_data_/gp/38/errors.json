[{"experiment_type":"vary_train_size","search_space":"darts","dataset":"cifar10","predictor":"gp","uniform_random":1,"test_size":200,"train_size_single":10,"train_size_list":[5,8,12,20,31,50,79,126,199,316,500],"fidelity_single":5,"fidelity_list":[1,2,3,4,5,7,10,13,17,23,30,40,54,71,95],"out_dir":"p301_35","max_hpo_time":900,"seed":38,"search":{"seed":1000,"batch_size":256,"data_size":25000,"cutout":false,"cutout_length":16,"cutout_prob":1.0,"train_portion":0.7},"eval_only":false,"resume":false,"model_path":null,"save":"p301_35/cifar10/predictors/gp/38","data":"/home/shalag/NASLib/naslib/data"},{"mae":0.5282809475232165,"rmse":0.6223136845186507,"pearson":0.2162312811115836,"spearman":0.21880827086505678,"kendalltau":0.14734246559972353,"kt_2dec":0.15232008807721895,"kt_1dec":0.061397254987459446,"precision_10":0.0,"precision_20":0.25,"train_size":5,"fidelity":5,"train_time":39213.566508,"fit_time":0.003773927688598633,"query_time":5.186915397644043e-05,"cv_score":0},{"mae":0.451300163269043,"rmse":0.564450412722246,"pearson":NaN,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":8,"fidelity":5,"train_time":61331.083102000004,"fit_time":0.002217531204223633,"query_time":4.928469657897949e-05,"cv_score":0},{"mae":0.44963364919025606,"rmse":0.5980236290983104,"pearson":0.013930703189219516,"spearman":0.00953185910779069,"kendalltau":0.007369577413620282,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":12,"fidelity":5,"train_time":95791.368332,"fit_time":0.0025949478149414062,"query_time":5.1033496856689456e-05,"cv_score":0},{"mae":0.44399733093999044,"rmse":0.5844166093227178,"pearson":0.00028397910749960716,"spearman":0.12446689319857827,"kendalltau":0.0899978261152894,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.1,"precision_20":0.05,"train_size":20,"fidelity":5,"train_time":164218.24271099997,"fit_time":0.002834796905517578,"query_time":5.078434944152832e-05,"cv_score":0},{"mae":0.4481743338800244,"rmse":0.56417933923211,"pearson":6.045647680653091e-15,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":31,"fidelity":5,"train_time":243632.32131499998,"fit_time":0.0033864974975585938,"query_time":5.1685571670532226e-05,"cv_score":0},{"mae":0.4426201248168942,"rmse":0.5682497493217575,"pearson":NaN,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":50,"fidelity":5,"train_time":403780.507141,"fit_time":0.019474029541015625,"query_time":0.00013626575469970702,"cv_score":0},{"mae":0.44758368045468844,"rmse":0.5642664752219471,"pearson":6.045647680653091e-15,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":79,"fidelity":5,"train_time":636281.4316179999,"fit_time":0.01956629753112793,"query_time":8.591771125793457e-05,"cv_score":0},{"mae":0.450346958220951,"rmse":0.5642615976957701,"pearson":6.045647680653091e-15,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":126,"fidelity":5,"train_time":1005704.875853,"fit_time":0.007638454437255859,"query_time":5.2802562713623047e-05,"cv_score":0},{"mae":0.446741356969479,"rmse":0.5645033346083188,"pearson":0.013236164775895976,"spearman":0.08747477671187068,"kendalltau":0.07170970021731786,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":199,"fidelity":5,"train_time":1587106.724448,"fit_time":0.011394500732421875,"query_time":5.551338195800781e-05,"cv_score":0},{"mae":0.42384377653979394,"rmse":0.5381904587446694,"pearson":0.33441971340964316,"spearman":0.3392585786718814,"kendalltau":0.22786683633445615,"kt_2dec":0.23095389300687175,"kt_1dec":0.24611713313346922,"precision_10":0.1,"precision_20":0.2,"train_size":316,"fidelity":5,"train_time":2520188.429482,"fit_time":0.020158052444458008,"query_time":6.0815811157226565e-05,"cv_score":0},{"mae":0.4481519539095957,"rmse":0.5629573389121444,"pearson":0.0979775518538033,"spearman":0.326027473851987,"kendalltau":0.21607540782886953,"kt_2dec":0.08952963610077294,"kt_1dec":0.09362437096337073,"precision_10":0.0,"precision_20":0.05,"train_size":500,"fidelity":5,"train_time":3967888.831019,"fit_time":0.03234267234802246,"query_time":7.57145881652832e-05,"cv_score":0}]