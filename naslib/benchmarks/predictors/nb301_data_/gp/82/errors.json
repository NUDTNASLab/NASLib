[{"experiment_type":"vary_train_size","search_space":"darts","dataset":"cifar10","predictor":"gp","uniform_random":1,"test_size":200,"train_size_single":10,"train_size_list":[5,8,12,20,31,50,79,126,199,316,500],"fidelity_single":5,"fidelity_list":[1,2,3,4,5,7,10,13,17,23,30,40,54,71,95],"out_dir":"p301_80","max_hpo_time":900,"seed":82,"search":{"seed":1000,"batch_size":256,"data_size":25000,"cutout":false,"cutout_length":16,"cutout_prob":1.0,"train_portion":0.7},"eval_only":false,"resume":false,"model_path":null,"save":"p301_80/cifar10/predictors/gp/82","data":"/home/shalag/NASLib/naslib/data"},{"mae":0.5482902908325196,"rmse":0.6767413881748178,"pearson":NaN,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":5,"fidelity":5,"train_time":37317.734693,"fit_time":0.004042863845825195,"query_time":5.1326751708984375e-05,"cv_score":0},{"mae":0.5285501766204018,"rmse":0.6658834070911921,"pearson":0.057907104524464015,"spearman":0.021826191096628374,"kendalltau":0.017650133075096438,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":8,"fidelity":5,"train_time":65315.548574,"fit_time":0.002389669418334961,"query_time":4.844784736633301e-05,"cv_score":0},{"mae":0.5389253721727345,"rmse":0.6688634208344643,"pearson":0.013185651843892938,"spearman":0.22950710865114632,"kendalltau":0.15532586431783685,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.1,"train_size":12,"fidelity":5,"train_time":97306.583288,"fit_time":0.0023431777954101562,"query_time":4.921436309814453e-05,"cv_score":0},{"mae":0.5475703430176168,"rmse":0.676024386150816,"pearson":0.001721970801702348,"spearman":0.0626415142177758,"kendalltau":0.050880304443663454,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":20,"fidelity":5,"train_time":157530.70545900002,"fit_time":0.0028111934661865234,"query_time":5.0411224365234374e-05,"cv_score":0},{"mae":0.557450356022004,"rmse":0.6856355158111924,"pearson":NaN,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":31,"fidelity":5,"train_time":250658.47946899998,"fit_time":0.0033631324768066406,"query_time":5.1887035369873046e-05,"cv_score":0},{"mae":0.5390902175903328,"rmse":0.6689758126373228,"pearson":NaN,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":50,"fidelity":5,"train_time":391261.185592,"fit_time":0.012562036514282227,"query_time":8.134126663208008e-05,"cv_score":0},{"mae":0.5355070712898344,"rmse":0.6668257667235183,"pearson":8.542444689777583e-16,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":79,"fidelity":5,"train_time":625493.8855059999,"fit_time":0.023432254791259766,"query_time":7.401704788208008e-05,"cv_score":0},{"mae":0.5339533133470846,"rmse":0.666266502791045,"pearson":0.018436429101021647,"spearman":0.015156122817899997,"kendalltau":0.012118675605362233,"kt_2dec":0.012118675605362233,"kt_1dec":0.02869589761730764,"precision_10":0.0,"precision_20":0.0,"train_size":126,"fidelity":5,"train_time":1003285.1646469999,"fit_time":0.008102178573608398,"query_time":5.666851997375488e-05,"cv_score":0},{"mae":0.536745015039529,"rmse":0.6678255622059487,"pearson":0.0278940513863657,"spearman":0.3219254218341909,"kendalltau":0.21563281766230374,"kt_2dec":0.023894179757645594,"kt_1dec":NaN,"precision_10":0.2,"precision_20":0.35,"train_size":199,"fidelity":5,"train_time":1577819.7483259998,"fit_time":0.011583805084228516,"query_time":5.517125129699707e-05,"cv_score":0},{"mae":0.5335482405947034,"rmse":0.6661953139390442,"pearson":0.024829703952613028,"spearman":0.02947522621781551,"kendalltau":0.023894179757645594,"kt_2dec":0.023894179757645594,"kt_1dec":0.037472546121950515,"precision_10":0.0,"precision_20":0.0,"train_size":316,"fidelity":5,"train_time":2510986.5824579997,"fit_time":0.0201718807220459,"query_time":6.372332572937011e-05,"cv_score":0},{"mae":0.524354057544791,"rmse":0.6598839339286071,"pearson":0.1506914485751615,"spearman":0.14914195391773735,"kendalltau":0.12225458121428132,"kt_2dec":0.12225458121428132,"kt_1dec":0.11917456450556542,"precision_10":0.0,"precision_20":0.05,"train_size":500,"fidelity":5,"train_time":3981870.636977,"fit_time":0.033159732818603516,"query_time":7.942795753479003e-05,"cv_score":0}]