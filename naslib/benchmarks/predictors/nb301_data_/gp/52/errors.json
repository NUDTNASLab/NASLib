[{"experiment_type":"vary_train_size","search_space":"darts","dataset":"cifar10","predictor":"gp","uniform_random":1,"test_size":200,"train_size_single":10,"train_size_list":[5,8,12,20,31,50,79,126,199,316,500],"fidelity_single":5,"fidelity_list":[1,2,3,4,5,7,10,13,17,23,30,40,54,71,95],"out_dir":"p301_50","max_hpo_time":900,"seed":52,"search":{"seed":1000,"batch_size":256,"data_size":25000,"cutout":false,"cutout_length":16,"cutout_prob":1.0,"train_portion":0.7},"eval_only":false,"resume":false,"model_path":null,"save":"p301_50/cifar10/predictors/gp/52","data":"/home/shalag/NASLib/naslib/data"},{"mae":0.6742796936035136,"rmse":0.8378277091465584,"pearson":7.157226047005907e-15,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":5,"fidelity":5,"train_time":41760.310331,"fit_time":0.004119873046875,"query_time":5.182027816772461e-05,"cv_score":0},{"mae":0.5300497817993164,"rmse":0.6710458886856693,"pearson":NaN,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":8,"fidelity":5,"train_time":66584.353777,"fit_time":0.002303600311279297,"query_time":4.831910133361816e-05,"cv_score":0},{"mae":0.4813165410359732,"rmse":0.5984968233037354,"pearson":0.029343383730306823,"spearman":0.0273953441529587,"kendalltau":0.0222510479475682,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.1,"precision_20":0.05,"train_size":12,"fidelity":5,"train_time":96433.288537,"fit_time":0.0025870800018310547,"query_time":5.011916160583496e-05,"cv_score":0},{"mae":0.4538748168945314,"rmse":0.5570041979008927,"pearson":7.157226047005907e-15,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":20,"fidelity":5,"train_time":163926.832475,"fit_time":0.00283050537109375,"query_time":6.795287132263183e-05,"cv_score":0},{"mae":0.45298959463352484,"rmse":0.555973341560889,"pearson":0.003654605288156122,"spearman":0.16874320749676835,"kendalltau":0.1106047772369637,"kt_2dec":0.06782916822054905,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.05,"train_size":31,"fidelity":5,"train_time":250559.12265,"fit_time":0.0033273696899414062,"query_time":5.003809928894043e-05,"cv_score":0},{"mae":0.45375983428955097,"rmse":0.5568673188797502,"pearson":NaN,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":50,"fidelity":5,"train_time":416030.480997,"fit_time":0.01530146598815918,"query_time":8.400797843933106e-05,"cv_score":0},{"mae":0.4575936020476914,"rmse":0.5628710789637342,"pearson":NaN,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":79,"fidelity":5,"train_time":648079.6650349998,"fit_time":0.01244664192199707,"query_time":6.46960735321045e-05,"cv_score":0},{"mae":0.4542469778831939,"rmse":0.5577358138109196,"pearson":0.01667823348555583,"spearman":0.017804535508971066,"kendalltau":0.014611463134344598,"kt_2dec":0.014611463134344598,"kt_1dec":0.014611463134344598,"precision_10":0.0,"precision_20":0.0,"train_size":126,"fidelity":5,"train_time":1005288.3535339999,"fit_time":0.007947444915771484,"query_time":5.5733919143676755e-05,"cv_score":0},{"mae":0.4527178476811527,"rmse":0.5559301351075187,"pearson":0.05583669613480527,"spearman":0.0645231351175526,"kendalltau":0.05279450337951946,"kt_2dec":0.05279450337951946,"kt_1dec":0.060461226762805236,"precision_10":0.0,"precision_20":0.0,"train_size":199,"fidelity":5,"train_time":1584849.44307,"fit_time":0.011331319808959961,"query_time":5.8509111404418946e-05,"cv_score":0},{"mae":0.4519414708361113,"rmse":0.5557289398159921,"pearson":0.055875770434457094,"spearman":0.04319551872049683,"kendalltau":0.03560359001019893,"kt_2dec":0.05279450337951946,"kt_1dec":0.060461226762805236,"precision_10":0.1,"precision_20":0.05,"train_size":316,"fidelity":5,"train_time":2522004.939425,"fit_time":0.01822495460510254,"query_time":6.062865257263183e-05,"cv_score":0},{"mae":0.4342545717558145,"rmse":0.5407131517566578,"pearson":0.24410683483509485,"spearman":0.3346312379713595,"kendalltau":0.2307050797576762,"kt_2dec":0.14987265436282043,"kt_1dec":0.15418902708342802,"precision_10":0.2,"precision_20":0.2,"train_size":500,"fidelity":5,"train_time":3997773.824096,"fit_time":0.03425431251525879,"query_time":7.367730140686035e-05,"cv_score":0}]