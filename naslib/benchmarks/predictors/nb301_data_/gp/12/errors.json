[{"experiment_type":"vary_train_size","search_space":"darts","dataset":"cifar10","predictor":"gp","uniform_random":1,"test_size":200,"train_size_single":10,"train_size_list":[5,8,12,20,31,50,79,126,199,316,500],"fidelity_single":5,"fidelity_list":[1,2,3,4,5,7,10,13,17,23,30,40,54,71,95],"out_dir":"p301_0","max_hpo_time":900,"seed":12,"search":{"seed":1000,"batch_size":256,"data_size":25000,"cutout":false,"cutout_length":16,"cutout_prob":1.0,"train_portion":0.7},"eval_only":false,"resume":false,"model_path":null,"save":"p301_0/cifar10/predictors/gp/12","data":"/home/shalag/NASLib/naslib/data"},{"mae":0.48182021331787067,"rmse":0.6082954884802995,"pearson":NaN,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":5,"fidelity":5,"train_time":40458.262514,"fit_time":0.00590968132019043,"query_time":5.698442459106445e-05,"cv_score":0},{"mae":0.47925014495849505,"rmse":0.6047670131728738,"pearson":0.010780338659975467,"spearman":0.06933526807765296,"kendalltau":0.05673992106845742,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":8,"fidelity":5,"train_time":67461.00901699999,"fit_time":0.0024063587188720703,"query_time":4.95302677154541e-05,"cv_score":0},{"mae":0.4959465604738946,"rmse":0.6276758705035539,"pearson":0.1672493520720693,"spearman":0.19282222491061246,"kendalltau":0.1306523243265942,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.3,"precision_20":0.25,"train_size":12,"fidelity":5,"train_time":101522.924543,"fit_time":0.0023708343505859375,"query_time":4.948139190673828e-05,"cv_score":0},{"mae":0.48678023529052694,"rmse":0.6153030859388771,"pearson":9.407559416207174e-16,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":20,"fidelity":5,"train_time":169455.863387,"fit_time":0.0028340816497802734,"query_time":5.064249038696289e-05,"cv_score":0},{"mae":0.4810389869314155,"rmse":0.6071087672677145,"pearson":0.10013412037001015,"spearman":0.07261528213319556,"kendalltau":0.054563271564217204,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.1,"precision_20":0.2,"train_size":31,"fidelity":5,"train_time":252397.075097,"fit_time":0.003322124481201172,"query_time":9.96696949005127e-05,"cv_score":0},{"mae":0.4804202774047808,"rmse":0.6063130573873046,"pearson":0.11500762301347658,"spearman":-0.0013427031292997116,"kendalltau":-0.0014501477435471713,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.1,"precision_20":0.05,"train_size":50,"fidelity":5,"train_time":394678.025216,"fit_time":0.01226496696472168,"query_time":0.00010644197463989258,"cv_score":0},{"mae":0.47932538443478356,"rmse":0.6048091896059093,"pearson":0.043453395999813724,"spearman":0.12388539618053668,"kendalltau":0.08479302677170224,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.1,"precision_20":0.1,"train_size":79,"fidelity":5,"train_time":616535.6166389999,"fit_time":0.013710975646972656,"query_time":8.561015129089355e-05,"cv_score":0},{"mae":0.47912398747035456,"rmse":0.6046194251511564,"pearson":9.407559416207174e-16,"spearman":NaN,"kendalltau":NaN,"kt_2dec":NaN,"kt_1dec":NaN,"precision_10":0.0,"precision_20":0.0,"train_size":126,"fidelity":5,"train_time":995553.3671389999,"fit_time":0.008041143417358398,"query_time":5.4398775100708006e-05,"cv_score":0},{"mae":0.47841849503086686,"rmse":0.6047398559474852,"pearson":0.04976234988473353,"spearman":0.0008597636613924556,"kendalltau":0.0013593146311445229,"kt_2dec":0.04233772443894781,"kt_1dec":0.04183486872534683,"precision_10":0.0,"precision_20":0.0,"train_size":199,"fidelity":5,"train_time":1572972.268106,"fit_time":0.011208295822143555,"query_time":5.4314136505126954e-05,"cv_score":0},{"mae":0.477022804877066,"rmse":0.6037694067252858,"pearson":0.05002788019933316,"spearman":0.2034926919436279,"kendalltau":0.13770916283188867,"kt_2dec":0.04233772443894781,"kt_1dec":0.04233772443894781,"precision_10":0.2,"precision_20":0.1,"train_size":316,"fidelity":5,"train_time":2488571.489206,"fit_time":0.0198671817779541,"query_time":6.029248237609863e-05,"cv_score":0},{"mae":0.4753796330799483,"rmse":0.60139415246702,"pearson":0.15553026783462778,"spearman":0.34766100749366263,"kendalltau":0.236706525863305,"kt_2dec":0.12931123447626441,"kt_1dec":0.14037854815578787,"precision_10":0.3,"precision_20":0.2,"train_size":500,"fidelity":5,"train_time":3939341.883463,"fit_time":0.03090381622314453,"query_time":7.661223411560058e-05,"cv_score":0}]